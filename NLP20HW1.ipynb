{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP 2020 - HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Gathering and Cleaning Up Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ptb_preprocess will assist us in cleaning up the data according to the given rules. First, let's introduce some functions that will help us edit the tokens list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all numbers by the token N\n",
    "def replaceNums(tokens):\n",
    "    return [\"N\" if nltk.tokenize.punkt.PunktToken(w).is_number else w for w in tokens]\n",
    "\n",
    "# Keep only the top-10K most frequent words in the dataset\n",
    "def keep_only_top_freq(tokens, most_freq):\n",
    "    return [w if (w in most_freq) or (w == \"N\") else \"<unk>\" for w in tokens]\n",
    "\n",
    "def remove_punc_helper(w):\n",
    "    punctuations = list(string.punctuation)\n",
    "    return \"\".join([l for l in w if l not in punctuations])\n",
    "\n",
    "# Remove all punctuations\n",
    "def remove_punc(tokens):\n",
    "    return [remove_punc_helper(w) for w in tokens if not remove_punc_helper(w) == \"\"]\n",
    "\n",
    "# change to lowercase\n",
    "def lower_case(tokens):\n",
    "    return [w.lower() for w in tokens]\n",
    "\n",
    "# Return an array of the top most frequent words in the dataset\n",
    "def get_top_most_freq(tokens,top):\n",
    "    fdistw = nltk.FreqDist(remove_punc(tokens))\n",
    "    return [w for (w, n) in fdistw.most_common(top)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ptb_preprocess will creata a two-dimensional array of tokenize words for every sentence, than it will use the functions defined above to edit the text and create the output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import nltk.data\n",
    "\n",
    "def ptb_preprocess(filenames, top=10000):\n",
    "    for fname in filenames:\n",
    "        f = open(fname, \"r\")\n",
    "        raw = f.read()\n",
    "\n",
    "        # create an array of the top most freqent words in the text, will be using it later:\n",
    "        most_freq = get_top_most_freq(word_tokenize(raw), top)\n",
    "\n",
    "        tokens = [word_tokenize(t) for t in sent_tokenize(raw)]\n",
    "\n",
    "        new_tokens = [(keep_only_top_freq(remove_punc(replaceNums(lower_case(s))), most_freq))\n",
    "                      for s in tokens]\n",
    "\n",
    "\n",
    "        new_tokens = [\" \".join(t) for t in new_tokens]\n",
    "\n",
    "        output = open(fname+ '.out', 'w+')\n",
    "\n",
    "        [output.write(sent+\"\\n\") for sent in new_tokens]\n",
    "        output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green green green blue blue <unk> <unk> N\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('a.txt', 'w+')\n",
    "f.write(\"Green green green blue blue red orange 100\")\n",
    "\n",
    "f.close()\n",
    "\n",
    "filenames = [\"a.txt\"]\n",
    "ptb_preprocess(filenames,2)\n",
    "\n",
    "f = open(\"a.txt.out\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the output is in lowercase, only the 2-most-frequent words 'blue' and 'green' remained, and the number \"100\" was replaced by the token 'N'. Let's look at another example where we can observe how words like \"don't\" and \"$12\" are splits into two words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do nt caller s N\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('b.txt', 'w+')\n",
    "f.write(\"don't caller's $12\")\n",
    "f.close()\n",
    "\n",
    "filenames = [\"b.txt\"]\n",
    "ptb_preprocess(filenames)\n",
    "\n",
    "f = open(\"b.txt.out\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run the function on 'Shakespeare works' and print the first 5 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen before we proceed any further hear me speak\n",
      "\n",
      "all speak speak\n",
      "\n",
      "first citizen you are all resolved rather to die than to famish\n",
      "\n",
      "all resolved\n",
      "\n",
      "resolved\n",
      "\n",
      "first citizen first you know <unk> <unk> is chief enemy to the people\n",
      "\n",
      "all we knowt we knowt\n",
      "\n",
      "first citizen let us kill him and we ll have corn at our own price\n",
      "\n",
      "ist a verdict\n",
      "\n",
      "all no more talking o nt let it be done away away\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "url = \"https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\"\n",
    "urllib.request.urlretrieve(url, \"shakespeare_input.txt\")\n",
    "\n",
    "filenames = [\"shakespeare_input.txt\"]\n",
    "ptb_preprocess(filenames)\n",
    "\n",
    "with open(\"shakespeare_input.txt.out\") as myfile:\n",
    "    [print(next(myfile)) for x in range(10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of what is a \"word\" thats adopted is Semantic. The tokens are split into independent units of meaning as we can obseve from the example word 'don't' which is seperted into 'do' and 'nt'. \n",
    "If we use a character level language model the definition of a word changes into an orthographic definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Gathering Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "\n",
    "def count_tokens(dataset):\n",
    "    return len(word_tokenize(dataset))\n",
    "\n",
    "def count_characters(dataset):\n",
    "    return len(dataset)\n",
    "\n",
    "def count_distinct_words(dataset):\n",
    "    return len(set((word_tokenize(dataset))))\n",
    "\n",
    "def count_most_N_frequent(dataset):\n",
    "    \n",
    "    most_frequent = (word for word in dataset.split() if not word == \"<unk>\")\n",
    "    return len(set(most_frequent))\n",
    "\n",
    "def token_type_ratio(dataset):\n",
    "    return count_tokens(dataset) / count_distinct_words(dataset)\n",
    "\n",
    "def dev_vs_train(dev_dataset, train_dataset):\n",
    "    set1 = set(dev_dataset)\n",
    "    set2 = set(train_dataset)\n",
    "\n",
    "    return len(set1.difference(set2))\n",
    "\n",
    "def avg_and_standart_deviation(dataset, characters_dataset):\n",
    "    mean = count_tokens(characters_dataset) / count_tokens(dataset)\n",
    "\n",
    "    sum = 0\n",
    "    for token in dataset.split():\n",
    "        sum += pow((len(token) - mean), 2)\n",
    "    standart_deviation = math.sqrt((sum / count_tokens(dataset)))\n",
    "\n",
    "    return (mean, standart_deviation)\n",
    "\n",
    "def diff_ngrams(dataset, n):\n",
    "\n",
    "    n_grams = list(ngrams(word_tokenize(dataset), n))\n",
    "    return len(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will discuss our expectations in comparison to the results. We will eaxmine the statistics of the ptb train dataset.\n",
    "\n",
    "Our expectaion for number of tokens is around 800,000. The dataset is 400,000 lines long and contains about 20 words in each line.\n",
    "\n",
    "Our expectaion for number of characters is around: the number of tokens * 5 = 800,000 * 5 = 4,000,000 since we expect the words to be not too short and not too long.\n",
    "\n",
    "Our expectaion for number of distinct words is around 5000. The document is in English which contains 171,476 words (according to the English dictionary). Apparently, not all English words appear in the text, but a 5 percent is a likely estimate.\n",
    "\n",
    "Our expectaion for number of tokens corresponding to the top-N most frequent words in the vocabulary is 10000 because we calculate the top 10000 frequent words.\n",
    "\n",
    "Our expectaion for number of token/type is around 200 becuase we believe that there are a lot of words that repeat theirselves.\n",
    "\n",
    "Our expectaion for number of types that appear in the dev data but not the training data is around 100 since the dev data is much shorter than the training data.\n",
    "\n",
    "Our expectaion for average number and standard deviation of characters per token is around 5 characters per token with standart deviation of 1.\n",
    "\n",
    "Our expectation for the total number of distinct n-grams (of words) that appear in the dataset for n=2,3,4 is around 800,000 - n + 1 for each n. Because in a text of |T| words this is the number of possible n-grams.\n",
    "\n",
    "Our expectation for the total number of distinct n-grams (of characters) that appear in the dataset for n=2,3,4,5,6,7 is around 800,000 * 5 - n + 1 for each n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of tokens is: 978726\n",
      "The total number of characters is: 5101618\n",
      "The total number of distinct words is: 9996\n",
      "The total number of tokens corresponding to the top-N most frequent words in the vocabulary is: 9998\n",
      "The token/type ratio in the dataset is: 97.91176470588235\n",
      "The number of types that appear in the dev data but not the training data is: 0\n",
      "The average number and standard deviation of characters per token are:  avg: 5.08356169142334 deviation: 2.5113567920948805\n",
      "The total number of distinct n-grams (of words) that appear in the dataset for n = 2 978725\n",
      "The total number of distinct n-grams (of words) that appear in the dataset for n = 3 978724\n",
      "The total number of distinct n-grams (of words) that appear in the dataset for n = 4 978723\n",
      "The total number of distint n-grams of characters that appear for n = 2 4975413\n",
      "The total number of distint n-grams of characters that appear for n = 3 4975412\n",
      "The total number of distint n-grams of characters that appear for n = 4 4975411\n",
      "The total number of distint n-grams of characters that appear for n = 5 4975410\n",
      "The total number of distint n-grams of characters that appear for n = 6 4975409\n",
      "The total number of distint n-grams of characters that appear for n = 7 4975408\n"
     ]
    }
   ],
   "source": [
    "text = open(\"simple-examples/data/ptb.train.txt\").read()\n",
    "characters_dataset = open(\"simple-examples/data/ptb.char.train.txt\").read()\n",
    "dev_dataset = open(\"simple-examples/data/ptb.valid.txt\").read()\n",
    "\n",
    "\n",
    "tokens = count_tokens(text)\n",
    "print(\"The total number of tokens is:\", tokens)\n",
    "characters = count_characters(text)\n",
    "print(\"The total number of characters is:\", characters)\n",
    "vocab = count_distinct_words(text)\n",
    "print(\"The total number of distinct words is:\", vocab)\n",
    "topn = count_most_N_frequent(text)\n",
    "print(\"The total number of tokens corresponding to the top-N most frequent words in the vocabulary is:\", topn)\n",
    "ratio = token_type_ratio(text)\n",
    "print(\"The token/type ratio in the dataset is:\", ratio)\n",
    "dev_not_train = dev_vs_train(dev_dataset, text)\n",
    "print(\"The number of types that appear in the dev data but not the training data is:\", dev_not_train)\n",
    "(avg, deviation) = avg_and_standart_deviation(text, characters_dataset)\n",
    "print(\"The average number and standard deviation of characters per token are: \", \"avg:\", avg, \"deviation:\", deviation)\n",
    "\n",
    "\n",
    "for i in range(2, 5):\n",
    "    n_grams = diff_ngrams(text, i)\n",
    "    print(\"The total number of distinct n-grams (of words) that appear in the dataset for n =\",i, n_grams)\n",
    "\n",
    "for i in range(2, 8):\n",
    "    n_grams = diff_ngrams(characters_dataset, i)\n",
    "    print(\"The total number of distint n-grams of characters that appear for n =\",i, n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens is 978726, which is pretty close to our estimation and thus is not very surprising.\n",
    "\n",
    "The number of characters is 5,101,618 which is longer in 100,000 than our estimation, meaning the text contained longer words than we expected.\n",
    "\n",
    "The number of distinct words is 9996 which is twice than what we expected and thus a little bit surprising.\n",
    "\n",
    "The number of tokens corresponding to the top-N most frequent words is 9998 which is very close to the number we assumed.\n",
    "\n",
    "The number of token/type is 97.91176470588235 which is about half than what we thought.\n",
    "\n",
    "The number of types that appear in the dev data but not the training data is 0 which is not much less than we thought.\n",
    "\n",
    "The average number and standard deviation of characters per token is (avg: 5.08356169142334 deviation: 2.5113567920948805) which is pretty close to out estimation.\n",
    "\n",
    "The total number of distinct n-grams (of words) that appear in the dataset for n=2,3,4 are indeed 978725, 978724, 978723\n",
    "\n",
    "As we can see the numbers of distinct n-grams (of characters) that appear in the dataset for n=2,3,4,5,6,7 are indeed 4975413, 4975412, 4975411, 4975410, 4975409, 4975408.\n",
    "\n",
    "Now one last thing is to check whether the Penn Treebank dataset follows the power law distribution. We will check this with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "\n",
    "text = open(\"simple-examples/data/ptb.train.txt\").read()\n",
    "\n",
    "plt.loglog([val for word,val in Counter(text).most_common(4000)])\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a relative change in frequency results in the proportional relative change in the rank, hence it follows the power low distribution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 n-gram Word Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import word_tokenize, ConditionalFreqDist, ConditionalProbDist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_word_lm(data, n=2):\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~ \" * (n-1)\n",
    "    data = pad + data\n",
    "    data = data.split()\n",
    "\n",
    "    for i in range(len(data)-n+1):\n",
    "        history, word = data[i:i+n-1], data[i+n-1]\n",
    "        history = \" \".join(history)\n",
    "        lm[history][word]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(words) for hist, words in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure used in the model is a dictionary where the keys are all the sequences of n words from the text and the values are counter objects used for the amount of times every word appeared after every sequence. The dictionary is of size at most the number of N-grams multiplied by the size of the vocabulary - so we get:\n",
    "O((|tokens| - n)* |vocabulary|)\n",
    "\n",
    "\n",
    "Let's test the function on a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('book', 1.0)]\n",
      "[('green', 0.6666666666666666), ('blue', 0.3333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "data = \"the book is green the book is blue the book is green\"\n",
    "\n",
    "lm = train_word_lm(data)\n",
    "print(lm[\"the\"])\n",
    "\n",
    "lm = train_word_lm(data, n=3)\n",
    "print(lm[\"book is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for \"is\" to appear after \"book\" is: \n",
      "1.0 \n",
      "\n",
      "The probability for \"green\" to appear after \"book is\" is: \n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LangModelI:\n",
    "    lm = \"\"\n",
    "    probDist = \"\"\n",
    "\n",
    "    def __init__(self,text, n=2):\n",
    "        self.lm = train_word_lm(text, n)\n",
    "\n",
    "    def get_most_likely_word(self, seq):\n",
    "        return max(dict(self.lm[seq]), key=dict(self.lm[seq]).get)\n",
    "\n",
    "    def get_prob(self,seq, word,):\n",
    "        p = dict(self.lm[seq]).get(word)\n",
    "        if p is None:\n",
    "            return 0;\n",
    "        return p\n",
    " \n",
    "\n",
    "\n",
    "data = \"the book is green the book is blue the book is green\"\n",
    "\n",
    "m1 = LangModelI(data)\n",
    "m2 = LangModelI(data,3)\n",
    "\n",
    "#using the model to get the probability of a word given an history sequence\n",
    "print(\"The probability for \\\"is\\\" to appear after \\\"book\\\" is: \")\n",
    "print(m1.get_prob(\"book\", \"is\"), \"\\n\")\n",
    "\n",
    "\n",
    "#using the model to get the probability of a word given an history sequance\n",
    "print(\"The probability for \\\"green\\\" to appear after \\\"book is\\\" is: \")\n",
    "print(m2.get_prob(\"book is\", \"green\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll update the class to include functions that will help us compute the preplexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangModelI:\n",
    "    lm = ''\n",
    "    prob_dist = ''\n",
    "    n = ''\n",
    "    estimator = ''\n",
    "    fileName = ''\n",
    "    text = ''\n",
    "\n",
    "    def __init__(self, fileName, n=2, estimator=None):\n",
    "        self.fileName = fileName\n",
    "        self.n = n\n",
    "        self.init_text()\n",
    "        self.lm = train_word_lm(self.text, n)\n",
    "        self.estimator = estimator\n",
    "        if self.estimator is not None:\n",
    "            self.init_prob_factory()\n",
    "\n",
    "\n",
    "    def init_text(self):\n",
    "        f = open(self.fileName, \"r\")\n",
    "        self.text = f.read()\n",
    "\n",
    "    def get_most_likely_word(self, seq):\n",
    "        return max(dict(self.lm[seq]), key=dict(self.lm[seq]).get)\n",
    "\n",
    "    def get_prob(self, seq, word):\n",
    "        if self.estimator is None:\n",
    "            p = dict(self.lm[\" \".join(seq)]).get(word)\n",
    "        else:\n",
    "            p = self.prob_dist[seq].prob(word)\n",
    "        if p is None:\n",
    "            return 0;\n",
    "        return p\n",
    "\n",
    "    def get_logprob(self, seq, word):\n",
    "        if self.estimator is not None:\n",
    "            return - self.prob_dist[seq].logprob(word)\n",
    "        else:\n",
    "            p = dict(self.lm[seq]).get(word)\n",
    "            if p is None:\n",
    "                return 0\n",
    "            return p\n",
    "\n",
    "\n",
    "    def init_prob_factory(self):\n",
    "        split_text = (self.text).split()\n",
    "        cfd = nltk.ConditionalFreqDist(\n",
    "            (\" \".join(split_text[i: i + self.n - 1]), \"\".join(split_text[i + self.n - 1]))\n",
    "            for i in range(len(split_text) - self.n + 1))\n",
    "\n",
    "        self.prob_dist = nltk.ConditionalProbDist(cfd, self.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_word_and_context_pairs returns the ngrams organized as pairs of (context, word).\n",
    "\n",
    "'perplexity' function compute the perplexity of the model by using the function 'get_entropy' and computing 2 ^ entorpy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_and_context_pairs(text,n):\n",
    "    pairs = []\n",
    "    for i in range(n - 1, len(text)):\n",
    "        context, word = tuple(text[i - n + 1:i]), text[i]\n",
    "        context = \" \".join(context)\n",
    "        pairs.append((context,word))\n",
    "    return pairs\n",
    "\n",
    "def get_entropy(lm, text, n=2):\n",
    "    sum = 0\n",
    "    pairs = get_word_and_context_pairs(text,n)\n",
    "    for (context, word) in pairs:\n",
    "        sum += lm.get_logprob(context, word)\n",
    "    return sum / (len(text) - n + 1)\n",
    "\n",
    "def perplexity(lm, text, n=2):\n",
    "    return 2 ** get_entropy(lm,text, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use it to get the perplexity values of the Penn Treebank dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287.21096735500424\n"
     ]
    }
   ],
   "source": [
    "lidstone_estimator = lambda fd: nltk.LidstoneProbDist(fd, 0.01, fd.B() + 100)\n",
    "lm = LangModelI('simple-examples/data/ptb.valid.txt', 2, lidstone_estimator)\n",
    "\n",
    "f = open(\"simple-examples/data/ptb.test.txt\", \"r\")\n",
    "test_text = f.read()\n",
    "test_text = test_text .split()\n",
    "\n",
    "print(perplexity(lm, test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to change the model to use a different estimators the class includes a function named init_prob_factory which creates the ConditionalProbDist object.\n",
    "\n",
    "now we can use it to get the perplexity of the trained model on the validation dataset for a variety of hyper-parameter gamna.\n",
    "The lower the perplexity the better the model so we'll try to find the best gamma by finding the one that give us the lowest perplexity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best gamma is:  0.73\n"
     ]
    }
   ],
   "source": [
    "f = open('simple-examples/data/ptb.test.txt', \"r\")\n",
    "test_text = f.read()\n",
    "test_text = test_text .split()\n",
    "\n",
    "gammas = np.array([])\n",
    "p_vals = np.array([])\n",
    "\n",
    "opt_gamma = 1\n",
    "min_p = 1000\n",
    "\n",
    "for i in np.arange(0.01, 0.99, 0.03):\n",
    "    gammas = np.append(gammas, i)\n",
    "    lidstone_estimator = lambda fd: nltk.LidstoneProbDist(fd, i, fd.B() + 100)\n",
    "    lm = LangModelI('simple-examples/data/ptb.valid.txt', 2, lidstone_estimator)\n",
    "    p_i = perplexity(lm, test_text)\n",
    "    p_vals = np.append(p_vals,p_i)\n",
    "    if p_i < min_p:\n",
    "        opt_gamma = i\n",
    "        min_p = p_i\n",
    "\n",
    "plt.plot(gammas, p_vals,'b')\n",
    "plt.show()\n",
    "\n",
    "print(\"The best gamma is: \", opt_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we would like to improve the model by using an n-gram model with increasing values of n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAef0lEQVR4nO3de3xcdZ3/8dcnSS+ZUOglEyi0TYpbLaJLhSwiSrdcBARW7i7dKuwuP0N/wgoKsoWqFLX7A7n5ABUsclNCBQUFFZTaIqwXwIAFWrG0hbYU2ia9pbSTNk3m8/tjJm0uk3SSueac9/PxmMec+Z5zvufT08k7J98554y5OyIiEiwlhS5ARESyT+EuIhJACncRkQBSuIuIBJDCXUQkgMoKXQBAZWWl19TUFLoMEZFB5aWXXtro7tFU84oi3GtqamhoaCh0GSIig4qZre5tnoZlREQCSOEuIhJACncRkQBSuIuIBJDCXUQkgAZ1uNfXQ00NlJQknuvrC12RiEhxKIpTIQeivh7q6iAWS7xevTrxGmDGjMLVJSJSDAbtkfvs2XuDvUMslmgXEQm7QRvua9b0r11EJEwGbbhPmNC/dhGRMBm04T53LkQiXb9FKhJJtIuIhN2gDfcZM2DePMNGrgFzqqth3jx9mCoiAoP4bBlIBPk3tnySKQdN4eHzHi50OSIiRWPQHrl3qKqoomlHU6HLEBEpKoM+3KORKI07GgtdhohIURn04V5VUaVwFxHpJhDhvjG2kfZ4e6FLEREpGoEId8fZ1LKp0KWIiBSNQIQ7oKEZEZFOFO4iIgGkcBcRCSCFu4hIAA36cB9dPpoSK1G4i4h0MujDvcRKiEaiukpVRKSTQR/uANGKKI0xHbmLiHQIRLjrKlURka4U7iIiARSMcI8o3EVEOttnuJvZvWbWaGZLOrWdb2ZLzSxuZrWd2mvMrMXMFicfd+Wq8M6qKqrYtmsbO9t25mNzIiJFL50j9/uBU7u1LQHOAZ5LsfxKd5+SfMzMsL60dJzrrjNmREQS9hnu7v4csLlb2+vuvixnVfWTLmQSEekqF2PuE83sr2b2rJkd19tCZlZnZg1m1tDUlNkRt8JdRKSrbIf7OmCCu38E+DLwkJntn2pBd5/n7rXuXhuNRjPaqMJdRKSrrIa7u+9y903J6ZeAlcD7s7mNVPaMucc05i4iAlkOdzOLmllpcvpQYBLwZja3kcp+Q/djWOkwHbmLiCSV7WsBM5sPTAMqzWwtcB2JD1jvAKLAr81ssbufAkwFvmFmbUA7MNPdN6fuOXvMTBcyiYh0ss9wd/fpvcz6eYplHwUezbSogVC4i4jsFYgrVEHhLiLSmcJdRCSAAhfu7l7oUkRECi5Q4b6rfRfvtb5X6FJERAouUOEOupBJRAQU7iIigRSYcI9GErcw0J0hRUQCFO46chcR2Ssw4R6tSBy5K9xFRAIU7sPLhrP/sP0V7iIiBCjcIXmue0zhLiISvHDXkbuIiMJdRCSIghXuEYW7iAgELdwrqtgY20h7vL3QpYiIFFTgwj3ucTa35Pz7QUREilqgwr3jXHd9l6qIhF2gwl1XqYqIJCjcRUQCSOEuIhJAgQr3MeVjMEzhLiKhF6hwLy0ppTJSqXAXkdALVLiDrlIVEYE0wt3M7jWzRjNb0qntfDNbamZxM6vttvw1ZrbCzJaZ2Sm5KLovCncRkfSO3O8HTu3WtgQ4B3iuc6OZfRC4ADg8uc73zaw08zLTp3AXEUkj3N39OWBzt7bX3X1ZisXPBH7i7rvc/S1gBXB0VipNk8JdRCT7Y+6HAG93er022daDmdWZWYOZNTQ1Ze+K0mgkSvOuZlrbW7PWp4jIYJPtcLcUbZ5qQXef5+617l4bjUazVkDHue76omwRCbNsh/taYHyn1+OAd7O8jT7pQiYRkeyH+xPABWY2zMwmApOAF7O8jT4p3EVEoGxfC5jZfGAaUGlma4HrSHzAegcQBX5tZovd/RR3X2pmjwB/A9qAS909rzdXV7iLiKQR7u4+vZdZP+9l+bnA3EyKyoTCXUQkgFeo7j9sf4aWDlW4i0ioBS7czSxxrntM4S4i4RW4cAddyCQionAXEQmgQIZ7NBLVRUwiEmqBDPeOI3f3lBfHiogEXmDDvaWthR27dxS6FBGRgghsuIPOdReR8FK4i4gEkMJdRCSAFO4iIgEUyHCPRhL3h1e4i0hYBTLcy4eUM2LoCIW7iIRWIMMdIFoRVbiLSGgFNtyrKqpoiukqVREJp0CHu47cRSSsghvuEYW7iIRXcMO9ooqmHU3EPV7oUkRE8i7Q4d7u7Wxp2VLoUkRE8i7Q4Q46111EwknhLiISQAp3EZEAUriLiATQPsPdzO41s0YzW9KpbbSZLTCz5cnnUcn2aWbWbGaLk4+v57L4voyJjAEU7iISTukcud8PnNqtbRaw0N0nAQuTrzv8r7tPST6+kZ0y+6+spIwx5WN0laqIhNI+w93dnwM2d2s+E3ggOf0AcFaW68oKXaUqImE10DH3A919HUDyuarTvI+Z2Stm9pSZHZ5xhRlQuItIWGX7A9WXgWp3PwK4A/hFbwuaWZ2ZNZhZQ1NTboZOFO4iElYDDfcNZjYWIPncCODu29x9e3L6SWCImVWm6sDd57l7rbvXRqPRAZbRN4W7iITVQMP9CeCi5PRFwOMAZnaQmVly+uhk/5syLXKgqiqq2LJzC63trYUqQUSkINI5FXI+8GfgA2a21swuBm4APmlmy4FPJl8DnAcsMbNXgNuBC9zdc1P6vnWc674xtrFQJYiIFETZvhZw9+m9zDoxxbLfBb6baVHZ0vlCpoNHHFzgakRE8iewV6iCrlIVkfAKdLhHI4kPahXuIhI2gQ73jiP3ph26SlVEwiXQ4T5y+EjKSsp05C4ioRPocDcznesuIqEU6HCH5IVMMYW7iIRLOMJdR+4iEjIKdxGRAAp+uEcU7iISPsEP94oqYrtj7GjdUehSRETyJhThDrqQSUTCJfDhHq3QVaoiEj6BD/c9V6nqu1RFJERCE+46cheRMAl8uOvmYSISRoEP94qhFVQMqVC4i0ioBD7cQRcyiUj4KNxFRAJI4S4iEkAKdxGRAApNuDfFmoh7vNCliIjkRSjCPRqJ0hZvY+vOrYUuRUQkL0IR7vouVREJm1CFu8bdRSQs0gp3M7vXzBrNbEmnttFmtsDMliefRyXbzcxuN7MVZvaqmR2Zq+LTpXAXkbBJ98j9fuDUbm2zgIXuPglYmHwN8ClgUvJRB9yZeZmZUbiLSNikFe7u/hywuVvzmcADyekHgLM6tf/IE54HRprZ2GwUO1CVkUpA4S4i4ZHJmPuB7r4OIPlclWw/BHi703Jrk21dmFmdmTWYWUNTU24/6BxSOoTR5aMV7iISGrn4QNVStHmPBvd57l7r7rXRaDQHZXRVVVFFY0zhLoNPfT3U1EBJSeK5vj6/66uP4u2jT+6e1gOoAZZ0er0MGJucHgssS07/AJiearneHkcddZTn2tT7pvrU+6bmfDsSHA8+6F5d7W6WeH7wwfz38eCD7pGIO+x9RCLp95Pp+uojl33EM+rD3R1o8F5y1RLz983MaoBfufuHkq9vAja5+w1mNgsY7e5Xm9npwGXAacBHgdvd/ei++q6trfWGhoa0fyENxHmPnMfSpqW8funrOd2OFIf6epg9G9asgQkTYO5cmDGjf+vX1UEstrctEoF589Lv58H6OJfUGbHY3j9my8vjfPv2rXz6/O20xdtoj7fT7u17nru3nXvsUWx4Z3iPvqMHx5i38GniHqc93k7c44lp7zQdb+fq0z/D5vUjeqw/6sBtzH7s7j3L9vX47r9dxbbGUT36GFG1mYvuu27Pco4nnt27vI57nMcuuZUdTZU9+iivbOTU787c5/ruzh++/CC7Nh3Uo4+ho9fxkRvPTrl+977e+OrTtG3pMUpM6ai1jPv6J7r00dv0lv/3V+Jbx/fow0auYfhVk/dst69nbnsLmmt69FFdDatW9WjulZm95O61qeaVpdnBfGAaUGlma4HrgBuAR8zsYmANcH5y8SdJBPsKIAb8R/ql5k5VRRXPrHqm0GVIGrITzL4nVFevhv/z+XaWb1rJcWe8TUtbCzvbdtKyu6XX6Xu/9HVisTFd+o3F4OLL13NHy1m0trd2eeyO7+7RFr91JcRquvTR0lLCf121jf96Z2J6/5h32lM2N707nLMfPnvf669P/eO3ZcN+XLXgqj5XLbESSqyEtsZvppz/XuNIHlryEIbtWdYsMd29bUfT6JR9tGysZMXmFT3W63jduW3XpqqUfbRuPpADhh/QY/3ufRnG37amPrejfesh/HPNP+9Zrrd+DOP7zeNS9uHN47n0ny7ds1xfz9+8vjplH2vWpGwekLSP3HMpH0fuc34/h+ufvZ7dX9tNWUlav9NkAHJxxDysvJ0vXP9Xppz8N5p3NrN151aadzUnpndtpXln897XO7ey4VsvQHOKH54DVsGX+g7VYaXDGF42nOZrNpP6I6k4p/z4NIaWDmVo6VCGlA5JTJcM7dE296Rvgqf4CMqce166j1IrpbSkdM9zWUlZj7bPTT2OxnfLe3Rx0CG7eKrh9T0BWGqle6dL9k4f++GDeeftnu/38ePjLF2+Y89y3R9me+uuqUn8guyuP0eZ6iP7fUDfR+5pj7nn8pGPMffvvfg9Zw6+7r11Od9WWKUzFtkeb/f17633l959yR//++P+/Re/79f+7lq/6OcX+Uk/OsnLRq3tsv6exwFvOXPY84jMjfjYm8f65O9O9mN+eIyf8uNT/DM//YzXPVHnWDxlH2Zxf3bVs/7i2hf9tQ2v+fJNy31t81rfFNvkO1p3eHu8fU+d1dUpaiDRnq5s9KExd/XRF/oYcy94sHuewv2nS3/qzMFfWf9KzrcVVr2FWaSy0Y+951ivvq3ah3xjSJeQZg5een2pj7t1nH/07o861t5rMK/YtMKbdjR5a1vrgOrIZ6hmq4+OfjL9ULbQHwyrj9z0oXB392dXPevMwResXJDzbQ1W6b7Z2uPt/taWt/w3y3/j3/nzd3zmL2f6tPunOaQOZmj34+8/3j/72Gd91oJZfscLd/hjf3vMX1z7or+z7R1va2/b03exBHN/9keu+xDpTV/hHprBZ92CoG/dx7pXr4bP1zmrm1dz6NTn+fvGv+95vLHpDVraWvasO2r4KCZXTqYiujnlGRHV1SUsumhRWnXMnZv6LJW5c9P/t3SM8Wcy9t/RT3/XyUUfIgOhcBcArrk2TizW9QPElpgx+1rgS9MxjImjJjK5cjInTjyRyZWTmVw5mQ9UfoBoJIqZUT88WMEsMpiFJtxHDh9JWUmZwj1pd/tuGt5tYOFbC1n01iLeXvO7lMvZtmpemfkqk8ZMYnhZz/OtO1MwixSP0IR7iZUQjUQDG+77OgUx7nFe3fAqi95axKK3FvHs6mfZ3rodgCkHTWFE1Vbea+x5LvKECcaHD/xw2nUomEWKQ2jCHSBaEcxwTzVeXlfnrN++noqjHmfhWwt55q1n2NSyCYD3j3k/n/vHz3HCxBOYVjONykgl9ftlPqQiIsUjVOFeVVEVyHCfPbtrKAPEYsZV/70LvvR/Gbf/OM54/xmcMPEETph4AuP273mFXbaGVESkOIQu3N/c8mahy8i6NWuclDfj3FbNG5e9wT+M/ocuVxz2RkMqIsERiu9Q7VAVCdaR++723dz5lzuxA9amnF89wZg0ZlJawS4iwRKucK+oYnvrdmK7Y/teuIjFPc5Drz3EYd87jC88+QUmnX8fw8q73mBK4+Ui4Ra6cAdo2pHbb37KFXfnyeVPcuQPjmTGYzPYb+h+PPlvT/L6D77GPXeXUl0NZombD/Xn1rQiEjyhG3OHxIVM1SNT33KzWP1hzR+4ZuE1/GHNH3jfqPfx0DkP8a8f+ldKLPH7WePlItJZaMN9sHh1w6tcu/Bafr381xy030HcefqdXPyRixlSOqTQpYlIEQvlsEyxhXuq71J8c8ubfPaxzzLlrin88e0/csOJN7DyiyuZWTtTwS4i+6Qj9wJLdQHSv1+8i/YzrmP4Rx5j1idm8ZVjv8Ko8p5fcyYi0ptQhXvF0ArKy8qLKtxTXYDUtmsY+z33Hd6479uMHZH6a8FERPoSqnCH5FWqseIJ996+M3HHxjGM7fm9xiIiaQnVmDskwr2YToWcMKF/7SIi6QhluBfTsMznv7IKhuzo0qYLkEQkUwr3Atreup0f+SmMPP9qxo1v1wVIIpI14Rxz39GIuxf8nitffOqLLN+0nIXfuovjJ5YWtBYRCZaMjtzN7HIzW2JmS83simTbHDN7x8wWJx+nZafU7KiqqGJ3fDfNu5oLWsf81+Zz3+L7mH3cbI6feHxBaxGR4BnwkbuZfQj4PHA00Ar8xsx+nZx9m7vfnIX6sq7zue4jh48sSA0rN6/kkl9dwsfHf5zrpl1XkBpEJNgyOXI/DHje3WPu3gY8C5ydnbJyp9AXMrW2tzL90emUlpRSf049ZSWhGxkTkTzIJNyXAFPNbIyZRYDTgPHJeZeZ2atmdq+Zpby00szqzKzBzBqamvJ3amKhw/2ri77KX979Cz/8lx8OupuXicjgMeBwd/fXgRuBBcBvgFeANuBO4H3AFGAdcEsv689z91p3r41GowMto9+ikcS2ChHuv13xW276001cctQlnPvBc/O+fREJj4w+UHX3e9z9SHefCmwGlrv7Bndvd/c4cDeJMfmiEa0oTLhv2L6BC39xIYdHD+e2U27L67ZFJHwyGvA1syp3bzSzCcA5wMfMbKy7r0sucjaJ4ZuiMbR0KCOHj8zrVapxj3PhLy5k265tLLpwEeVDyvO2bREJp0w/zXvUzMYAu4FL3X2Lmf3YzKYADqwCLslwG1mX7/vL3PKnW3h65dPcdfpdHF51eN62KyLhlVG4u/txKdo+l0mf+ZDPq1RffOdFrl10Lecedi51R9XlZZsiIqG7/QDkL9y37drG9Eenc/CIg7n7X+4u+BWxIhIe4Qz3SO7D3d2Z+auZrN66mvnnzteXbYhIXoUz3Cuq2BTbRFu8LWfbuH/x/cxfMp850+Zw7Phjc7YdEZFUQhvujrMptikn/S/buIzLnrqMaTXTuOYT1+RkGyIifQltuENuznXf1baLCx69gPKych48+0FKS3S3RxHJv1De2CSXFzJdveBqFq9fzC+n/5JD9j8k6/2LiKRDR+5Z9Mtlv+T2F2/n8o9ezhnvPyOrfYuI9Eeow70plvlVqvX1UFMDJSXOWcdMYcLqWdx40o0Z9ysikolQhvvo8tGUWEnGR+719VBXB6tXg7sR3zqexp/M5WcPD8tSpSIiAxPKcC+xEqKRaMbhPns2xGJd23a2lDB7dkbdiohkLJThDtm5SnXNmv61i4jki8I9AxMm9K9dRCRfFO4ZuPzaDTBkR5e2SATmzs2oWxGRjCncM/CnUZcx9KzLOGR8G2ZQXQ3z5sGMGVkqUkRkgEIb7tFIlPda36Nld8uA1v/jmj/ys7/9jNmXTmTtmjLicVi1SsEuIsUhtOGeybnu7s6VT1/JwSMO5sqPXZnt0kREMhb6cB/I0MzDSx/mhXde4FvHf4uKoRXZLk1EJGOhD/f+fpfqzradzPrdLI448AguPOLCXJQmIpKxUN44DAZ+5H7HC3ewunk193z6Ht3xUUSKVuiP3PsT7htjG5n7v3M5fdLpnHjoibkqTUQkY6EN9/2G7sfwsuH9Cvfrf38921u3c9Mnb8phZSIimQttuJtZ4lz3WHrhvmzjMu566S7qjqrjsOhhOa5ORCQzoQ136N+FTFf/7mrKy8qZM21ObosSEckChXsa4f77Vb/niWVPcM0nrtkzVi8iUswyCnczu9zMlpjZUjO7Itk22swWmNny5POo7JSafenc9jfuca58+komHDCBK465Ik+ViYhkZsDhbmYfAj4PHA0cAZxhZpOAWcBCd58ELEy+LkodR+7u3usy9a/W8/K6l/mfE/6H8iHleaxORGTgMjlyPwx43t1j7t4GPAucDZwJPJBc5gHgrMxKzJ2qiipa21vZtmtbyvmx3TGuXXQttQfXMv3D0/NcnYjIwGUS7kuAqWY2xswiwGnAeOBAd18HkHxOOUhtZnVm1mBmDU1NmX+X6UDs6/4yt/35NtZuW8utJ99KiYX64wkRGWQGnFju/jpwI7AA+A3wCtDWj/XnuXutu9dGo9GBlpGRvi5kWr99PTf88QbOnnw2x1Ufl+/SREQyktHhqLvf4+5HuvtUYDOwHNhgZmMBks+Z3TQ9h/oK9zm/n8POtp3ceNKN+S5LRCRjmZ4tU5V8ngCcA8wHngAuSi5yEfB4JtvIpd7CfWnjUu5++W4u/adLmTRmUiFKExHJSKY3DnvUzMYAu4FL3X2Lmd0APGJmFwNrgPMzLTJXopHEcFD3cP/Kgq+w/7D9+drUrxWiLBGRjGUU7u7eYzDa3TcBg+KuWsPKhnHAsAO6hPuClQt4asVT3PzJmxkTGVPA6kREBi70p4B0vkq1Pd7OlU9fyaGjDuWyoy8rcGUiIgMX2vu5d4hW7L1K9f7F9/Na42s8ct4jDCsbVuDKREQGTkfuySP37a3b+eozX+XY8cdy3gfPK3RZIiIZUbhHEuF+859uZv329dxy8i2YWaHLEhHJSKiHZerr4eEv30Bz4518Y+RajrlwDMeMO6bQZYmIZCy0R+719VBXB82No4ASfOsEXrn7UurrC12ZiEjmQhvus2dDLNa1raWlhNmzC1OPiEg2hTbc16zpX7uIyGAS2nCfMKF/7SIig0low33uXIhEurZFIol2EZHBLrThPmMGzJsH1dVglnieNy/RLiIy2IX6VMgZMxTmIhJMoT1yFxEJMoW7iEgAKdxFRAJI4S4iEkAKdxGRADJ3L3QNmFkTsDqHm6gENuaw/2wZLHXC4KlVdWbXYKkTBk+tmdRZ7e7RVDOKItxzzcwa3L220HXsy2CpEwZPraozuwZLnTB4as1VnRqWEREJIIW7iEgAhSXc5xW6gDQNljph8NSqOrNrsNQJg6fWnNQZijF3EZGwCcuRu4hIqCjcRUQCKDDhbmbjzewZM3vdzJaa2eUplplmZs1mtjj5+HqBal1lZq8la2hIMd/M7HYzW2Fmr5rZkQWo8QOd9tNiM9tmZld0W6Zg+9PM7jWzRjNb0qlttJktMLPlyedRvax7UXKZ5WZ2UQHqvMnM/p78v/25mY3sZd0+3yd5qHOOmb3T6f/3tF7WPdXMliXfr7NyWWcftT7cqc5VZra4l3XzuU9TZlLe3qfuHogHMBY4Mjk9AngD+GC3ZaYBvyqCWlcBlX3MPw14CjDgGOCFAtdbCqwnccFEUexPYCpwJLCkU9u3gVnJ6VnAjSnWGw28mXwelZwelec6TwbKktM3pqoznfdJHuqcA1yVxntjJXAoMBR4pfvPXT5q7Tb/FuDrRbBPU2ZSvt6ngTlyd/d17v5ycvo94HXgkMJWNWBnAj/yhOeBkWY2toD1nAisdPdcXkXcL+7+HLC5W/OZwAPJ6QeAs1KsegqwwN03u/sWYAFwaj7rdPen3b0t+fJ5YFyutp+uXvZnOo4GVrj7m+7eCvyExP9DzvRVq5kZ8Blgfi5rSEcfmZSX92lgwr0zM6sBPgK8kGL2x8zsFTN7yswOz2theznwtJm9ZGZ1KeYfArzd6fVaCvuL6gJ6/2Ephv3Z4UB3XweJHyygKsUyxbZv/5PEX2mp7Ot9kg+XJYeP7u1l+KDY9udxwAZ3X97L/ILs026ZlJf3aeDC3cz2Ax4FrnD3bd1mv0xiaOEI4A7gF/muL+nj7n4k8CngUjOb2m2+pVinIOesmtlQ4NPAT1PMLpb92R/FtG9nA21AfS+L7Ot9kmt3Au8DpgDrSAx3dFc0+zNpOn0fted9n+4jk3pdLUVbv/ZroMLdzIaQ2In17v5Y9/nuvs3dtyennwSGmFllnsvE3d9NPjcCPyfxp21na4HxnV6PA97NT3U9fAp42d03dJ9RLPuzkw0dw1fJ58YUyxTFvk1+QHYGMMOTg6zdpfE+ySl33+Du7e4eB+7uZftFsT8BzKwMOAd4uLdl8r1Pe8mkvLxPAxPuybG2e4DX3f3WXpY5KLkcZnY0iX//pvxVCWZWYWYjOqZJfLi2pNtiTwAXJs+aOQZo7vgzrgB6PRIqhv3ZzRNAx1kFFwGPp1jmt8DJZjYqOcxwcrItb8zsVOC/gU+7e6yXZdJ5n+RUt895zu5l+38BJpnZxORfeReQ+H8ohJOAv7v72lQz871P+8ik/LxP8/GpcT4ewCdI/NnyKrA4+TgNmAnMTC5zGbCUxCf6zwPHFqDOQ5PbfyVZy+xke+c6DfgeibMQXgNqC7RPIyTC+oBObUWxP0n8wlkH7CZxlHMxMAZYCCxPPo9OLlsL/LDTuv8JrEg+/qMAda4gMZ7a8T69K7nswcCTfb1P8lznj5Pvv1dJBNLY7nUmX59G4kyQlbmus7dak+33d7w3Oy1byH3aWybl5X2q2w+IiARQYIZlRERkL4W7iEgAKdxFRAJI4S4iEkAKdxGRAFK4i4gEkMJdRCSA/j/KzHWDBHOtvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best n is: 3\n"
     ]
    }
   ],
   "source": [
    "f = open('simple-examples/data/ptb.test.txt', \"r\")\n",
    "test_text = f.read()\n",
    "test_text = test_text .split()\n",
    "\n",
    "opt_n = 0;\n",
    "min_p = 1000\n",
    "n_vals = np.array([])\n",
    "p_vals = np.array([])\n",
    "\n",
    "for i in range(2, 21):\n",
    "    n_vals = np.append(n_vals, i)\n",
    "    lidstone_estimator = lambda fd: nltk.LidstoneProbDist(fd, opt_gamma, fd.B() + 100)\n",
    "    lm = LangModelI('simple-examples/data/ptb.valid.txt', i, lidstone_estimator)\n",
    "    p_i = perplexity(lm, test_text, i)\n",
    "    p_vals= np.append(p_vals,p_i)\n",
    "    if p_i < min_p:\n",
    "        opt_n = i\n",
    "        min_p = p_i\n",
    "\n",
    "\n",
    "plt.plot(n_vals, p_vals,'g')\n",
    "plt.plot(n_vals, p_vals, 'bo')\n",
    "plt.show()\n",
    "\n",
    "print(\"The best n is:\", opt_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the best predicted n-gram model based on a Lidstone model with the optimized gamma parameter and of the best possible n order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.9751006368645\n"
     ]
    }
   ],
   "source": [
    "lidstone_estimator = lambda fd: nltk.LidstoneProbDist(fd, opt_gamma, fd.B() + 100)\n",
    "lm = LangModelI('simple-examples/data/ptb.valid.txt', opt_n, lidstone_estimator)\n",
    "\n",
    "print(perplexity(lm, test_text, opt_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best preplixty we could find online is 46.6 which is better than the one we got-  87.9751.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Generating Text from a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def create_word(model, history):\n",
    "    r = random()\n",
    "    for word, prob in model[history]:\n",
    "        r = r - prob\n",
    "        if r <= 0 :\n",
    "            return word\n",
    "\n",
    "\n",
    "def generate(model, seed):\n",
    "    history = \" \".join(seed)\n",
    "    out = []\n",
    "    for i in range(0, 100):\n",
    "        c = create_word(model, history)\n",
    "        history += \" \" + c\n",
    "        history = history.split()\n",
    "        history = history[1:]\n",
    "        history = \" \".join(history)\n",
    "        out.append(c)\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on our model, for n=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade despite objections from southern african governments which threatened to find alternative channels for selling elephant <unk> the move by the convention on trade in endangered <unk> meeting in switzerland places the elephant on the <unk> election campaign he interviewed mr. <unk> head of stock-index futures last week traders said brokerage firms as a rule do n't comment on their market activity unlike the week following black monday two years ago individual traders in the s&p N futures pit to await the opening bell traders were shouting bids and offers that were a full point apart said one s&p N\n"
     ]
    }
   ],
   "source": [
    "f = open(\"simple-examples/data/ptb.valid.txt\", \"r\")\n",
    "text = f.read()\n",
    "\n",
    "lm = train_word_lm(text, 4)\n",
    "print(generate(lm, [\"ban\", \"on\", \"ivory\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating when the seed is shorter that the history length of the n-gram model maybe can be done by adding a random word from the vocabulary to the seed, or basing the implementation regardless of the history. We might want that the genration will stop when the text is shorter than the original text, so if our model is good it will generate a readable text but if it is not, we will stop in time to see what we can fix.\n",
    "Now let's generate segments on 5 different seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the task it is <unk> listening for the now generation mr. glass has constructed his solo program around a move from the simple to the relatively complex opening N from <unk> <unk> the <unk> the report by the defense ministry also rejected allegations that britain covered up evidence of <unk> 's activities as a german army officer an international group approved a formal ban on ivory trade despite objections from southern african governments which threatened to find alternative channels for selling elephant <unk> the move by the convention on trade in endangered <unk> meeting in switzerland places the elephant on\n",
      "\n",
      "national taxpayers union it <unk> in the world series tomorrow replacing the debut commercial of shearson 's <unk> black-and-white where we stand commercials which have been running occasionally in response to news events since N the ad would have run during the world series last weekend the team that dumped runs by the bushel on the chicago board of trade futures contract of N stocks stood at N down N points in fact it was up N points at N its high for the day of across the country now use massage chairs in the workplace as well as by\n",
      "\n",
      "the <unk> of receivables owed to national heritage by some of the big program trading firms would hold off until the market stabilized they did n't the dow accelerated its slide losing N in the first six months of living expenses set aside in the bank most investment advisers say individuals also should focus on building equity in a home which provides some protection against inflation as well as to concern about the loan 's security the bank syndicate is made up mostly of european banks but it includes china 's state-owned <unk> industrial bank the N banks in the\n",
      "\n",
      "trying to <unk> by concentrating on <unk> output such as coated and <unk> products for industrial and transportation applications citing a $ N billion in <unk> to various arab <unk> for <unk> rights around the indian ocean he dedicated all these new forces to the persian gulf and indian ocean marshall figured it would be good training for those soldiers someday maybe they would get the whole navy they had fun moving the carriers around but it turned out that they had forgotten all about mine <unk> but the shah still kept leaping out at cap so cap bought a\n",
      "\n",
      "the british version shows a handful of processors and may take a week or more to be processed and returned black-and-white film costs consumers a little less <unk> after friday 's jolt in the market as it was falling they then had no choice in many cases but to sell the paintings the acquisitions officials said in a letter to mr. paul 's holdings are <unk> that is he is being <unk> and <unk> the cost but right now programmers are figuring that viewers who are busy dialing up a range of health issues dr. novello an expert on pediatric\n"
     ]
    }
   ],
   "source": [
    "print(generate(lm, [\"especially\", \"hard\", \"at\"]))\n",
    "print()\n",
    "print(generate(lm, [\"statement\", \"of\", \"the\"]))\n",
    "print()\n",
    "print(generate(lm, [\"specially\", \"made\", \"for\"]))\n",
    "print()\n",
    "print(generate(lm, [\"N\", \"east\", \"germans\"]))\n",
    "print()\n",
    "print(generate(lm, [\"mr.\", \"fromstein\", \"said\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that as we change the seeds we see different results that are based on the words created from the given history as a seed. For example, in seed like the first there is a discussion about certain task, which makes sense in relation to something that is \"especially hard at\".\n",
    "The last text talks about a person \"he\" which is reasonable given the seed \"mr. Fromstein said\" which \"mr. Fromstein\" is a proper name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temperature argument can control the level of variability generated by the model by that it increases the probability of each word and thus changes it, so the word is not necessarily the most likely one to be chosen and some words that are less common in a given context can be chosen over the others.\n",
    "The code in the method generator.py from Sameer Sing corresponds to the mathematical explanation provided in the blog by that it calculates the probability of the word, then divides it by the temperature, then calculates the sum of log2 of (2 ^ the quotient + 2 ^ the previous quotient), then for each result again calculates the sum of log2 of (2 ^ each result + 2 ^ the previous result), then raises 2 by the power of the differences between the two sums and if it greater then the random number then the word is being chosen. So the temperature increases each probability and then affects the next word that will be chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Character language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy Summary:\n",
    "\n",
    "In the article we can observe that RNN language models are able to generate different texts using an input related to a certain field. For example, receiving different inputs of code samples, it can create code blocks that probably wont compile, but will be perfectly indented and will have balanced brackets, meaning it supplies a very good frame to a code and in addition a code that is very close to a code that works. The thing that is most surprising in the experimental results reported in the blog is that while the common belief at the time the results were published was that RNNs were difficult to train, it is in fact pretty easy and powerful. We witness that by the results of the experiments shown in the article, such as the code block we discussed earlier, a Wikipedia text that the model generated pretty close to the origin, Shakespeare monologues that even though we can see its not a Shakespeares real text, the model still created pretty good monologues in an eloquent English. Another interesting result is of creating a Latex sampled algebraic geometry. It teaches us that the model is quite good at learning complicated syntactic structures. In conclusion, RNNs are good models to use for training.\n",
    "\n",
    "The unreasonable effectiveness of Characters-level Language Model By Yoav Goldberg Summary:\n",
    "\n",
    "This article discusses the power of language models that do not use smoothing (unlike RNNs models that do use smoothing). The main claim of the writer is that unsmoothed maximum likelihood characters level language models have effectiveness on generating convincing natural language outputs. The unsmoothed maximum likelihood characters level language model works as follows. It calculates the probability of each character to appear next to a history of n characters according to the total number of times the history characters appear in the text in the same order. The article presents a few examples to how the using of that kind of model generates different English texts like a text based on Shakespeares sample. It shows that as greater the n as better the text the model generates. The writer is mostly impressive by the context awareness of the model. He says that the model succeeded in learning the context by the history given, for example learned well how to create nested brackets and indented blocks within a code. Finally, the writer tries the model on Linux-kernel code. On these results, he is not very satisfied by the results of the maximum likelihood characters level language models and thus concludes that LSTM, one of RNNs that uses smoothed language models, is doing its job well on texts like this, and thus summarizes that he is impressed by RNNs after all.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will gather the recipes dataset and prepare a dataset reader according to the structure of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_preprocess([\"neural_net_cooking_recipes.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic statistics about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of recipes in the dataset is:  62\n",
      "The number of tokens in the dataset is:  14857\n",
      "The number of characters in the dataset is:  67256\n",
      "The size of the vocabulary of the dataset is:  1102\n",
      "The distribution of the size of recipes in words in the dataset is:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZgb53Xm+x7sW+8bm83m3hQpahclUZJlx5LtSHZi2Uk0Wa81thJlkZP4OjOOM3PnJpln4jjzzI0dZ3FGsWPJk9jxFltKIsvR6kU7ZW2kSJHs5tZcemV3Yy9U1Xf/qPoKBaAKKABVaKD7+z0Pn0YX0EABLJw69Z73O4cYYxAIBALB2sK32jsgEAgEAvcRwV0gEAjWICK4CwQCwRpEBHeBQCBYg4jgLhAIBGuQwGrvAAAMDg6yrVu3rvZuCAQCQUfx8ssvzzPGhqzua4vgvnXrVhw4cGC1d0MgEAg6CiI6ZXefkGUEAoFgDSKCu0AgEKxBRHAXCASCNYgI7gKBQLAGEcFdIBAI1iAiuAsEAsEaRAR3gUAgWIOI4C4QCNYEj705g5mV3GrvRtsggrtAIOh4FJXh1//PAXz1xdOrvSttgwjuAoGg45FkFSoDspKy2rvSNtQM7kR0CRG9avq3QkQfI6J+InqMiI7pP/v0xxMRfY6IjhPR60R0jfdvQyAQrGckWQUA5PWfAgfBnTH2FmPsKsbYVQCuBZAB8G0AnwTwBGNsAsAT+u8AcAeACf3fvQA+78WOCwQCASevaBl7riAyd069ssxtACYZY6cA3AngQX37gwA+oN++E8CXmcbzAHqJaNSVvRUIBAIL8gWRuZdTb3D/BQBf1W+PMMbOA4D+c1jfPgbgjOlvpvVtJRDRvUR0gIgOzM3N1bkbAoFAUERSeHAXmTvHcXAnohCA9wP4Rq2HWmxjFRsYu58xto8xtm9oyLIdsUAgEDjC0NwLInPn1JO53wHgx4yxGf33GS636D9n9e3TAMZNf7cJwLlmd1QgEAjsEAXVSuoJ7r+IoiQDAA8DuFu/fTeAh0zbP6S7ZvYDWObyjUAgEHgBl2VEQbWIo0lMRBQD8G4Av27a/GkAXyeiewCcBnCXvv0RAO8FcByas+bDru2tQCAQWCAy90ocBXfGWAbAQNm2BWjumfLHMgD3ubJ3AoFA4ABeSBUF1SJihapAIOh4ROZeiQjuAoGg4+FBXWjuRURwFwgEHY/I3CsRwV0gEHQ8xiIm4XM3EMFdIBB0PMXMXYHm6RCI4C4QCDoeLseoDJBVEdwBEdwFAsEaQDJp7aKoqiGCu0Ag6HjMwV0UVTVEcBcIBB0PL6gCIrhzRHAXCAQdT0nmLmQZACK4CwSCNUC+RHMXmTsggrtAIFgDmHvKiP4yGiK4CwSCjkcUVCsRwV0gEHQ8IrhXIoK7QCDoeCRFhd+nTfgUBVUNEdwFAkHHI8kquiLaeIqcyNwBiOAuEAjWAHlZRXckqN0WmTsAEdwFAsEaQJJVdEe1zF1o7hoiuAsEgo5HklV0hfXMXQR3ACK4CwSCNYCkFDV34XPXcBTciaiXiL5JREeI6DAR3UhE/UT0GBEd03/26Y8lIvocER0noteJ6Bpv34JAIFjvSLKKBC+oihWqAJxn7n8B4FHG2G4AVwI4DOCTAJ5gjE0AeEL/HQDuADCh/7sXwOdd3WOBQCAoIy+rCAf8CAV8InPXqRnciagbwNsBfBEAGGMSY2wJwJ0AHtQf9iCAD+i37wTwZabxPIBeIhp1fc8FAoFAJy8rCAd8iAR8YtSejpPMfTuAOQBfIqJXiOgLRBQHMMIYOw8A+s9h/fFjAM6Y/n5a31YCEd1LRAeI6MDc3FxTb0IgEKxvJFlFOOBDOOgXBVUdJ8E9AOAaAJ9njF0NII2iBGMFWWyrmHvFGLufMbaPMbZvaGjI0c4KBAJBOYwxSIqKUMCHcMAnfO46ToL7NIBpxtgL+u/fhBbsZ7jcov+cNT1+3PT3mwCcc2d3BQKBoBRZZWAMCPn14C4ydwAOgjtj7AKAM0R0ib7pNgBvAngYwN36trsBPKTffhjAh3TXzH4Ay1y+EQgEArfhTcO0zN0vCqo6AYeP+20A/0hEIQBTAD4M7cTwdSK6B8BpAHfpj30EwHsBHAeQ0R8rEAgEnmAO7pGgyNw5joI7Y+xVAPss7rrN4rEMwH1N7pdAIBA4ggfzcMCvZe7CLQNArFAVCAQdToksE/QhJ2QZACK4CwSCDkdStGBedMuIzB0QwV0g6DgeeOYEnjwys9q70TZwWSbk9yESFAVVjgjuAkGH8Xc/PIFvvXx2tXejbZAMzV1YIc2I4C4QeMzXXjqN7x264NrzpSUZObFQx6DcCik+Gw0R3AUCj/m7H57A/3nulGvPl8kromhoIi8yd0tEcBcIPCaTlzGfyrvyXJKsQlJU0dbWRLlbRgR3DaeLmAQCQYOkJQUFtaK9UkNkJS1jF9JDEUkxLWIK+KGoDLKiIuBf37nr+n73q8B3XjmLex54abV3Q9BCMpKMxbQE1YUAn5ZkACK4m5FMbplwUAtpInsXwb3lvHzqIn5wTLQ4Xi9IsoqCwqCoDEvZQtPPlzGCuwhenPKCKiBOfoAI7i0nV1CML7tg7cODMQAsuKC7p/Na0BJe7iJ5xdx+QGTuHBHcW0y2IDTT9URaKv4/z6ckF55PZO7l8P7tWuMwLXMXwV0E95aTE8F9XZHJmzL3tHuZezsfP5NzKSy7IEE5RVJKrZCAuLIBRHBvOTzjyonMYl1gztwXXMjcucwj646QduTn//fz+NvvT7bs9awKquLKRgT3liNkmfVFSebuouYOtGeCICsq5lN5LLpwInOKJKsI+Ag+HxkFVTFqTwT3lsN9yllJHHzrgRLNPe1e5g60Z4KwktP2L23aT6+RZG1+KgBRUDUhgnuL4cvGhSa4PuDBOOT3uZ+5t2Nw17X2ViYvkqIaQV0UVIuI4N5icsYKQ3HwrQd4MN7UF3VVcwfa8xjihdRWZu75glXm3n4nvlYjgnuLEZr7+oIH4/H+GBZckGXSbS7LLK9S5l4M7nwRU/ud+FqNCO4tphjcxcG3HuCZ++b+mCvNwzImWaYds1Me3DOtDO6yipDeR6bYfqD9PptW4yi4E9FJInqDiF4logP6tn4ieoyIjuk/+/TtRESfI6LjRPQ6EV3j5RvoJBhjRStkG2ZdAvfJSDLCAR9GusNI5prvw55uc1lmJdf64J6XVYT0jN2QZdrws2k19WTu72SMXcUY26f//kkATzDGJgA8of8OAHcAmND/3Qvg827tbKdjLvKIftzrg7QkIx4OYCARBgAsNinNZCQFQT8BaM8EoZi5t9AtY5JlREG1SDOyzJ0AHtRvPwjgA6btX2YazwPoJaLRJl5nzWDWIYUVcn2QySuIhfwYiIcANL+QKZ2X0a8/Vztm7sWCagsz94JiZOxcnhGyjPPgzgD8OxG9TET36ttGGGPnAUD/OaxvHwNwxvS30/q2EojoXiI6QEQH5ubWR5dEc7YuMov1QVqSEQ8VM/f5JlsQZCQF/XHtudoxc1/Jahm7JKsta45ntkL6fISQ39eWJ75W4zS438wYuwaa5HIfEb29ymPJYlvF/zJj7H7G2D7G2L6hoSGHu9HZmLP1dvxiekGuoCCVb90leruRkRTEwn4MJlzK3CXZuApoR2lvxdRTplXSjLmgCkAftdd+n02rcRTcGWPn9J+zAL4N4HoAM1xu0X/O6g+fBjBu+vNNAM65tcOdTLaw/oL7H//LoXU9nCSdL83cm13IlM4rHSHLAK0rqppXqAJAOOgXV8ZwENyJKE5EXfw2gPcAOAjgYQB36w+7G8BD+u2HAXxId83sB7DM5Zv1jvnL2I5fTC+YvpjF1Hx6tXdj1chImuYeD2m9xpv1updq7u2XIKxKcFfKgnvAJ9wycDZDdQTAt4mIP/4rjLFHieglAF8nonsAnAZwl/74RwC8F8BxABkAH3Z9rzuU3DrM3HMFBRfTEhhj0I+hdQV3yxARBhPhprzusqIiL6vojQVB1J7H0EqugGjQj2xBQbpFclyFLBP0taVk1WpqBnfG2BSAKy22LwC4zWI7A3CfK3u3xihxy7ThF9MLMpICWWVYycroiQVXe3daDnfLAMBAItSU5p7Rj5lEOIBIwN+WwX05W8BobwRTc+mWHeN5WTUWLwHaKlWRuYsVqi2FZxMBH60bWYaf0Jp1iXQqPHMHgIF4qKmBHXx1aiwUQCTYfo4QVWVYyRYw2hMB0GLN3e83fhcFVQ0R3FsID3S9sdC6Ofj4F7zZxTudiKJqK5J55j6YCDeVufPVqfGwH5Fg+2XuKUmGyoAN3VEApb3svaS8oBoJ+kRBFSK4txT+ZeyLBdvui+kV3A7nRkfEToO/93hIz9z14K4plw08n565x0MBLbi3WQDjNshWZu6MMYuCqnDLACK4txR+Gd0bC7bdJbVXcN11PWbuPLjFwjxzD0FSVGOgRb3wzD0W1pw37ZYgcKfMBh7cW7B/5vmpHM0t016fzWoggnsNnp9awH/59huuPBcPdL2xUNt9Mb2goKgoKFqWurgONXfuFilm7nwhU2OfhflKoB1lmeXyzL0Fsox5fipH+Nw1RHCvwZNHZvGVF06j4MIw4mxBQcBHSIQD68KqZXZLuNHLvNMwMnfultHbBjT6WfD2wZrm3n5ebi7LjHS3TpbhQdzslomIzB2ACO41SeqX0G7YunIFBdGgVgzLSu31xfQCs/VzPcoyRuYedjdzjxmae3sFMN5XpjcWRDTob0n7AevMXRRUARHca8K/oG50ccwVFERCPOtqry+mF5gzt/VZUC3N3Ad587AGP4u0uaDahj53Lsv0RIOIhfwtydyN4F5WUG23z2Y1EMG9BrzplRsHalZSEAn62jLr8gKeuRGtT1mmaF3UMve+WHPNw/jnGdUThHYryi9nC/CRtsgqFva3pK01L6hWtB8QmbsI7rVI5Xhwb/4SM1dQNVkm4EdBYS1ribpa8C/3hu7IuiyoFhcdaZl7KOBDTzTY8EKmVF5ByO9DKOBr24JqdzQIIkIsGGjJkGxLWSbgh6wyyC7UyToZEdxrkHJRlskamrv2sbfbl9Nt+NXOeF8Mi+nG/d2dSrrM5w4014IgI8mGrbIdg/tKroCeqNZiIhZujSxTLKgWV6jy75ckgrugGq7KMgUFEb2gCqyf4L6pL4qCwpBcZ33dy33uAJpqHpbOK8aJQmuO1V7BazlrCu4t0tz5Su/yfu6AmKMqgnsN3AzueSO4ax/7Wm8exk9em/q05eiL66yoms7LCOiTgTiDiVDD9YeMJBsSTyTghySrUNtI2jMH92gwsHoFVZ48rYO6VjVEcK+BIcsUms86syYrJLD2e7rzL/eYHtybaZrVifBe7uZWxwPxJjJ3SUFML8624yDo5WwB3REtuMfDfmRbqLmXr1AFROYugnsV8rJiHDxuyTKa02G9yDLal3tTXwzA+rNDZkwdITkDiRCWMoWGFsVl8jIShubefnWblayMbpMs04oh2VZumXY88a0GIrhXgfuKAbd87qphhQTW/oT2rFQmy6wzO2RaKvZy5/Bxexcb+Cy05yvN3NtFemBMa/db1NwDrbFCWrpl9My9TT6b1UIE9yqYJ8m4EtwlXXMP8KxrbWcWGb3dAl+Ovt687pl8ZeY+qI/Ia2QhU0aSEQ+VZ+7tcQzlCiokRS0pqKYl2XOHlGTRfiAcEJk7IIJ7VZKm7n1udLir1NzXdmaRlYoyVDzkF5k7ipl7I/WHdL6ouUfb7Bjiq1O7o/r+hfxgzPsAm7dpPwC0z2ezWojgXoWUi5l7QVEhq6zMCrm2Mwuzu6M/EVp3wV3LtCs1d6Cx+oM5cw+3WXBfyRVbDwBFb7/Xjhnr9gOioAqI4F6VVN48yb25yj//EkbXkRUyW1ANjbg/Hl6Hskwx0+YMxnl/mfoyd1VluvtG19wD7ZUgmPvKAFrmDsDzIdmioGqP4+BORH4ieoWI/lX/fRsRvUBEx4joa0QU0reH9d+P6/dv9WbXvSelF1SJms9AeCCPhPxtd0ntFVlJNt7rQDzUcDfETiVtyrQ53dEAgn6q+0THj594uVumTYqGy5nS4M6v2LxOYCxlGVFQBVBf5v67AA6bfv8zAJ9hjE0AuAjgHn37PQAuMsZ2AviM/riOhPeV6Y+FmpZl+CViJOBru0tqr8jomjsA9MfXoSyTL2baHCLCQDxc94mOZ8AVbpkWDaGuhaG5R1ovy4T8vpK1BOE2u6pZLRwFdyLaBOB9AL6g/04AbgXwTf0hDwL4gH77Tv136PffRuZPvoPgssxQV9i1zJ139APW/mVjxlRQHIhrKzPXS38ZxpiWuYf9Ffc10l+Ge8bjpt4yQPtk7uWaOz+pez2NSZLVkgVMgMjcOU4z988C+AQAHo0GACwxxvj/3DSAMf32GIAzAKDfv6w/vgQiupeIDhDRgbm5uQZ331u4LDPUFW7aLcMz/2jQr2caaz9zz0qKIcv0x0OQZLUlC1vagbysQmWoyNwBzTFTr+Zembm3lxWy6JZpbeael5USvR0QmjunZnAnop8CMMsYe9m82eKhzMF9xQ2M3c8Y28cY2zc0NORoZ1tNKidrvalDzS+l5oE8EtSWo7fjsAW3yRSKbhluAVwv/WWKU5gqM/fBeKhunzsPkvGKgmp7HEPL2QK6wgH4fdrX3yioetyCQJLViuAeEm4ZAM4y95sBvJ+ITgL4J2hyzGcB9BIRT0s2ATin354GMA4A+v09ABZd3OeWkcoX9ODefBOkrCm4az/bb9iC22g+d33EnL54Z730l8mYrtTKGUiEsJDO1yVR8SAZK5dl2uQY4r3cOUZB1WvNXakM7n4fIegnIcvUegBj7A8YY5sYY1sB/AKAJxljvwzgKQA/pz/sbgAP6bcf1n+Hfv+TrEOF1nReQSISQDTUfJZttkIC2pdzrVshzZp7vx7c10tRtXwKk5mBRBi5glpXwpDJl2bu4UB7LdQx95UBWl9QLUcbtdceJ77Vohmf++8D+DgRHYemqX9R3/5FAAP69o8D+GRzu7h6JPXl47Fg872p+YHGtdJoGw5bcBPGGLKFyuC+XpqHpcumMJkZaOCzKJ4stOfz+QihgK99CqrZAnqixROZUVBdBVkG4KP22uOzWS0q04oqMMaeBvC0fnsKwPUWj8kBuMuFfVt1UjlNR4yFtCybMYZGjT9mtwygrTBcy5lFXlbBWPH9Gisz10nmnqmSuRuDstN5bB6IOXu+fOVUp0jA1za68nK2gK2DxfcSCvgQ9JP3mbtS6ZYBtCtjUVAV2JLOK0iEA4iGAmCsOX0zK5XLMms7syjXnGOhACJB37qZpVo1c2+gBQF3GZmnOrXTqD1zL3dO1IUr3lrkC9UydxHcBTakdFkmqkspzVxi8stno6C6xt0y/LMyB7eBddSCIGMxP5VjNA+rww6ZkSqnOrVTcDfPT+VoRgRvZZm8oiIUqDyBhgK+tvlsVgsR3KuQzBXQFQkY3uJmshC+kpBfQq51t4xxpWIKbutplapVps0pOofqyNzzlVOdWn0M3fePP8Y/vXi6YntB0YrDFcG9BUOybQuqQpYRwd0ObYUhl2Wa75PB2/3yL+dad8sYw6FNVsCBddQZ0koj50SCfnSFA3UtZLKa6hQJ+ltaUH3s8Ay+e/BCxXajaVisPHNvRXBXrDX3gA/5Nfz9coII7jbkCioUlWluGaPy30Tmrk9h4rTTJbUXGMHdJMv0x+tfdt+ppKv43AHtRFfPQiar3vCtlPZyBW3k5NGZZMV95X1lOK2QZax87oDI3AER3G1J6n1luM8daE5z55k7J+KSW0aSVSRzhdoPbDG5MncQwPvLrI+Caiavrc71+azdVb2xEJYy9cgylZl7uIWyzJLe9fH8cs4I5pyVsna/nFZk7vmCtVtGFFRFcLeFd4TsChc192ZW22ULCiIhc3B357Lxs48fxZ1/9UzTz+M2xczdrLnzxTveZnPtgHneqRU90WBFkKxGJm+Rubfw6m8pWzwRHSvL3sv7ynBaIsvYZe5ClhHB3Q5uZXNNlpEUox8I4J5eOjmXwtR8uu5GVF5j7ZZZPwuZMjYdITm9sfqCe9piqlMrvdw8cweAt2yCu5VbxvP2A1VWqIrMXWCJIcuEA4ac0kwBNCcrJRJFJOBHQWFQ1OY6M3Dd9q0LlVroalLeSwdYXy0I0ha93M30RIMlAbMWGalyqlOkhXY/874eLTvWVsrmp3L4kGwvsVuhutbXkThBBHcbDFkmEnClCZK5/S1gbtna3AHIvdKHz6809TxuY1lQTayf4J6xmMJkpicaxEquANXhyT2dr3y+VsoyPICPdIdxpDy4698Va5+7d/unqgyyymxkGX/brN5dLURwt8Hc+MkNn3vWwi2jbW/u4OeZ++Hz7ZW5W3VF5PND18NCprRFpm2mJxoEY1r/IidkLDT8VvrcueZ+/bYBHJ1JlnS0XM4WEAn6jAlInFjID0lWISve7COfn1r+uoBebBaZu8AKnrknwoHiQOsmLjHzBaVEonBjjmquoCClB4cjF9orc89KMiJBX4lbpN9Ydt9e9QEvyFhk2mZ4lrvsQJrhU50SYYvMXVZaMt1qKVNAwEe4erwXFzMFzJn+D5czlatTgeJVW7ODbuzgmbldQdUN2bOTEcHdBp5RdUUCIKKm+2SUWyHDLkzS4UXUvlgQx2ZSnmVIjaB1hCzNNOMhP0IB3zqRZapr7r0x7UTnpKiaK2hN2Co096AfjBUzWC9ZymoBfPeGLgDA0Qsp4z6rvjIAXHGZVSOvaM9rJ8sAmia/XhHB3YZ0XobfR4aHNhbyN5WBZMsy94gLmTuXZG7aOQhJUXFiPt3wc7lNpqzGAPDh0KF1IstUd8vwTNdsMaz2XAAqrgSKPd29D2DL2QJ6YkHs0oO72TFj1VcGKGbuaY/mqPLAHbZwyxTnFK9faUYEdxv4iD3eLiAa8jeVgeQKZW4ZY85j48/J5Y237RwEABxuI8dM1mJFJbB++stkHLhlAGeZeyZfuWYAKC4Qa4WfezlTQG80iMFEGIOJEN4yyYDLWevgHnXBQlwNHtyrZe7r2Q4pgrsNybwW3DnagozGMhBVZXr7AbMV0j1Z5oZt/Qj4CEfayDGTkUpPZpz+dZC5S7IKSVGrau69MefBvXxQB6c4R7UVsoxkSEm7Rrrw1kypLGMV3Lkv36seSlyOstPcgfaZVLUaiOBuQzovoytinizTuK2LZw+Wbpkmshouy4z2RLFzOFFhUVtNyq2fnIF4aM33dOf/p7XcMgAced2LC8IqNXcALXGFLJmKprtGunBsJmnYOMvnp3KirZJlLHvLcFlGZO6CMlJlvTxiwcZlmfL5qYA7X8z5VB7xkB/RkB+7N3S1V+ZekG0GVYSxuMZXqNpp5GYiQT/CAZ/hH6/6fMZq6XK3DHdxtUCWMWXnl2zoQkZScHYpC1VlSOVly+DO99ezgmoVWYZf1axnr7sI7jZwzZ3DR+01QtYiuBetkI0ffAspCYNdmnd892g3zi3nHFnrWoGdW6Q/HkJaUtb05bKRaVfJ3AHnq1R55mubuXv8WcqKimRONqSkS3hR9UISyZwMxioXMAFALKjtb9przd2yn7soqIrgbkMqLyNRIss0nrlbLcV3Y4XqfCpv9GvhFrV28bvnbDT3RgZVdBpGpl0lcwecNw/jwbGyt4x+DHksPfAVqL16AJ8YTgDQHDN2fWWAoizTzPqQanRaQfXoTLKl1syawZ2IIkT0IhG9RkSHiOiP9e3biOgFIjpGRF8jopC+Paz/fly/f6u3b8EbUnkZiVB5QbU5WSZS4nNvPutaSEnGsOU9o90A0Da6e6Zg75YBsKalmbSNRl6O0+ZhxSuBcitkazJ33pqYD+PoigQx1hvFWxeSWMnxXu6V75XLMl65ZarJMu1WUF3KSHjvX/wQ33nlbMte00nmngdwK2PsSgBXAbidiPYD+DMAn2GMTQC4COAe/fH3ALjIGNsJ4DP64zqOVK40c29m8IBVb/OICwWf+VTemMc53BVGXyzYNpm7nVvGGA69houqGRuNvJyeaBBL9WjuqyTL8BNQbzRkbLtkQxeO1sjcue7tmSyjdE5BdTaZh6wyTF/MtOw1awZ3psF9T0H9HwNwK4Bv6tsfBPAB/fad+u/Q77+NzIMfOwBVLY7Y40Sb0dwl3S1jOghDfh+IGv9iyoqKxYyEIT1YEhF2b+iuq8fM/T+YxL1fPtDQ61dDURkkWTU0VzP9en+Ztex1d5q590RDjgqqGUkGUanbCjAlCB4XDZcsxujtGunC5FzKsOOWj9gDAJ+PtFqVx7KMVW8Zo6DaJpr7Rf14n2/hce9IcyciPxG9CmAWwGMAJgEsMcb4/9o0gDH99hiAMwCg378MYMDiOe8logNEdGBubq65d+Ey/MuZKHPLFBSGQgNLva0ydyJCJNC4jn8xUwBjMDJ3ANg92oW3LiQddxp8bnIBzxyfb+j1q8GvcKKhysNrPbT95TKEo8zdwTSmdF5BPBRAeY7UKiskL9L3mrLz3Ru6UFAYXjuzDMA6cwd421+vZJkq7QdadOJzykX9M2xlXyVHwZ0xpjDGrgKwCcD1APZYPUz/aZWlV0Qbxtj9jLF9jLF9Q0NDTve3JfBmXOUFVaAx/dDKLQPoXf0a/GLyjGnQFNz3bOhGtqDg9KKzS7/ZZB5pSXHdh8xPWFGLzLU7EkDQT2u6oGo1hcqKnmgQaUmpmTDYDf5olSxjaO7R0swdAF46uQigcn4qp9mV3dWo6pZpUT3CKfwzbOWgmrrcMoyxJQBPA9gPoJeI+NG7CcA5/fY0gHEA0O/vAbDoxs62CnNHSE6x8t94cI+UBfdoE3NU+UEymCjqoLtH63PMzCa1E4TbU5yM4GaxiImI9EHZrdfcP//0JP7m6eOev07GsC5Wz9y5tbCWNJOWlAq9HXBnlbMTlrOV/dq3D8Xh9xEOnVtGQJdfrIh7OCS7ulumvTR3I3NvJ1mGiIaIqFe/HQXwLgCHATwF4Of0h90N4CH99sP679Dvf5K1oiepixiZe5nPHWhsSHbeJrg3M2yBB2SzLLNrpAs+ctbbXVZU4zk8C1OuCiAAACAASURBVO42X/j+eLjlskxGkvG5J47hLx4/Vtd4u0ZISwpCAR+CFhmlmWLzsOr7k8nLFU4ZAAj4fQj4yPvMPSuhKxxAwPR+IkE/tg7EoOoed7uyWtTDOaqdFNx55t7KcZhOMvdRAE8R0esAXgLwGGPsXwH8PoCPE9FxaJr6F/XHfxHAgL794wA+6f5ue4ulLBNsfGBH1kJzBzQ7ZKNZFz9IhkzBPRL0Y9tg3FHmvpCWwE+5c0l3Dzi798tZjc6Qj705g2xBQV5W8S+vnav9B01QawoTx2nzsLQk20o8kSaOIacsZwqWBVO+mMlObwd45u6dW4YICPgqTyz8xNc2BVU9uCdzcsu87tVFQQCMsdcBXG2xfQqa/l6+PQfgLlf2bpWwkmWMUXsNZElWbhmguTmP8ykJQT9VzK3cPdqNg2eXa/79zErOuO16cK+hOQ93h/H8ZMryPq946NVzGO2JoDsSxDcOnMGv7N/i2WvVmp/K4QGz1qrijKQYi7/KaaZu45Qlm8Zgl4x045E3LqCrSnCPhvyencglWUU44LO9aggHfG1XUAU0M8GGnojnrylWqFpQTZZpRHPPyQqCfiq5rAXQlFtmIZXHQDxccWDv2dCFUwuZmkXS2ZViQJ9zuchTbHRlnb2O9UZxYSXXkPOoERbTEn5wdA7vv3Ij/sN143htetnT9QB2BdByHGfuedm2lUE44P0c1eVswagPmLlkg7ZStVrm3kw31VrkZdWymMoJ65Oq2gGzK6pV0owI7hZYBfem3DKSUqG3A827ZQYSldnc7g3aSlXzMAUreDHVR97JMlbvGdCCu8qAC8s5y/vd5pE3zkNWGd5/1UZ88OoxBP2EbxyY9uz10jWmMHF6HQd3xVbmiQS9z06XMlLJAiYOd8xUD+7eyTJ5WUXIwuPOabfMfairtTOERXC3gMsyJV0hjd7U9WchuYJdcG9Gc5dKbJAcwzFTo6g6s5IDEbB9KOF6cK9VUB3riwIAzi5lXX1dOx5+9RwmhhO4dLQb/fEQ3n3pCL79ylnPtM9M3lnm3u2w7W9tzd37zN1Kc98yEEc06Ee/xX2cWMhvuIfchssydkSC/rYqqO4c0q50WuUUE8HdgpQkIxTwlVThY01k7rmCdW/zaBNfzAWbzH2sN4qucKCm7DCbzKM/FsJoT6Rk2LEb1AzuvXpwv+h9cD+7lMWLJxdx51UbDQnrrn3jWExLeOLwjCev6TRzD/p9iIf8VTN3xhgykmJ7soh4LD0wxkp6uZvx+whf+vB1uPcdO2z/Pq6Pp/TCMCcpqqVThhMONF7TchP+Ge4c5sFdZO6rRiono6tM42zW524V3Bt1yzDGMJ+SSpwyHCLC7tGumpn77EoOw90RDCXCmHe9oMpXqFoHpI29rcvcuTPm/VeOGdvePjGEDd0RfP3AGU9eMyNZ97K3ojcWqjpHNS+rUFRWJXP3eeqWyUgKZJWVrE41s3/7gHGytiIaCoAxbyyJkqxUzdzDAW8/G6ck8zJklWFzfwwhvw/zLeqrJIK7BeXtfoHi6tLGrJBqRV8QgOul9T9fMi9DUlRLWQYAJka6cHS2tuY+3BXGUFcYc6m8q5lVtqDA7yPbYlck6MdgItySzP07r5zF1Zt7sXkgZmzz+wg/e+0Yvn90zhPd36lbBtCkmWqLmIxWBnaau8cFVe7BtyqoOsHLIdmSXCtz97dF5r6ULn6GA4mQyNxXk3TZ/FRAu4QO+qlhWcZWc2/g4OOZtpUsAwCb+2NYyhSQzNkHjdlkDiPdWnCXZNXo2e0GGUlBLOi3tagBmu7udeb+1oUkjlxI4s4rN1bcd9e141AZ8K0fu19YdepzB7SiajVZxhjUYeOW8Vpzt2o9UA/NyJm1qO2W8bWF5s497n2xEAYSrRsQL4K7Bclc6Yg9TjTYWIe7XMG6/W0koDUjk+u0BPJqu13mPt6nZalnFq2Dp6IyzCXzGO6KGM/hZlE1a9Pu18ymXu+D+8OvnYXfR3jfFZXBfetgHDds68fXD5xx9apFVTWNvNYUJk6taUzFzN3GCumxLMM9+D0Wbhkn8CsYL4K7o8y9DWQZI7jHgxiIh0VBdTVJ5Ss1d6BxW1dWUowWpGYanaRTK3Mf79c00DM2vaMX0nmoTFtMxO1ZbnpvtRF71YM7z9y96kzBGMNDr57DzTsHjfdYzn/YN45TCxm8eMK91kfcBuo0c681jcmYx1qloOql9LDcrCxjDOzwQJapVVBtYpGgmxQ/wxAG4iFjsL3XiOBugZXmDui2rgYugXOyTebeYFc/3hPaqqAKmDN36+DOFzANd0WMwOdm5p6x8fWbGeuNQpJVzw70H59ewvTFrKUkw7nj8g1IhAP4xsvuSTNph/NTOb2x6gM7ioM/bGSZgLftB5rW3IPeDcmWaskybVJQ5b3cuSyzkHa3xmWHCO4WpPM2skzIj1xDmbtqGeyijQZ3PRD32SxJ740FkQgHMG1TsJxNakXE4e6wcYJwVZYp1HaLeO2YefjVswgHfHjP3hHbx8RCAdwyMWi0rXWDjMP5qZzuaBCSrNoeA+kaq301t4yXmrv9pCUncFnGi57ukqwa4yqt0AqqbRDcMwUQaZ/hQCKMXEH1bGGXGRHcLUhaWCGBxueoagVV+4EC9WYX86k8+mJB266DRIRNfdGamftIdwQ90SACPnLV655x4PP22uv+8umLuH5bP7ps+oxzLhvrwamFjDELtFmcTmHi8IzYTprhcoad5h4N+iGr9ddtnLKUlRDy+yytvE7wUpapVVBtpneTmyxlJHRHgvD7qDggvgXSjAjuZRQUFXlZrXDLAJpntyFZxsbn3qgss5CSSlr9WjHeH7PV3GdWih0lfT7CoMtedycF1eIqVW9mSp5ZzGKLyf5ox6UbtXYNb55zp9eM0ylMnJ4aq1T5/FSrlr+AeRqTN8F9RV+d2uikTM/dMjWtkO2RuffpJ3FuYGiF110E9zK49cxKlok14JYpKCpklbka3OdT+ZIhHVaM98VwZtG6YDmbzKEvFjS+GNzr7hbZQu2Cak80iK5wwJPMfTlbwHK2gM39tYP7Xj24H3IpuBvWRYeZe63mYbUyd35F6NW0o6VMwXYBkxNiNq2yGWN4159/H1965kTDz+1kEZMkq47HTnrFxYyEnpj2fTUGxIvMvfUkc5W93DmNyDLVmmg1OklnIW3dV8bMeH8U2YJi2aRoZiWPke5iy9GhrrDrBVUnKzS98rpzOYoXlqvBi8qHztVuk+yEejN33pDLbpZqKm89opETbjBBcIpd6wGnFFd2lyZFpxczOD6bwvePNj4/2Ylbhj9uNVkyZe78irsVdkgR3MvgHSGtNPdG5kHyL13ETbdMMl87uFdxzMwlcyX2wMFEyH2fe7B25jrWG7Ut+jaDEdwdZO6Alr27JcsYV35uZe55rTjtsxhIARSPIa+05SWbdr9O0SZSUUVB9Q195sDBs8sNO0dquWW4/Xi1ve4XMxL6eObONfcWLGQSwb2MqrJMA5l7Th/UUVWWqeOLmSsoSObl2rKMHtjOWATP2WRl5r6Qlly5fNUaXcmIhmofWp5l7hfrD+7HZlOuZL+1mqaV01OjoFqrCZnXc1RXsoWGFzBxYqFARVL0xrQW3OdTklEDqgdZUaEyVJdlgnzU3uoWVZcyxRNkJOhHPOQXssxqkLQYsceJBv3IFpS6gmBRlqn8qItWSOdfTH7Gr1VQ3aQXLMszd9VYnVr8+6FEGIrKjJV0zZCXtS+dE815rDeKZE52zanCOb2YQU806FhO2LuxB4rKcLRGD3wnFBcdOcvcu8IBEFXX3KtJPI1e/TllKSM1lbkD1gM73ji7bHwnnEwOKydfZX4qJ8wz91UsqkqyilReNjJ3QPvuLoiCauvhvdytZRltW72ZNmCXuftKHuMErtXVkmXi4QAG4iFMlzlmFjMSZJWVZe7abTeKqjxDc2KdMxwzLkszZxazxipdJ7hZVM3kFfioekZpxucjdEfsV6nWakIWaSBBcIokq0hLSlOaO6DJmWZZhjGGN84u447LRkEEHGyg3lFtODYnHKj/++U2vONnn+kE2armYTWPQCIaJ6KniOgwER0iot/Vt/cT0WNEdEz/2advJyL6HBEdJ6LXiegar9+Em9SSZYD6bF3ZKsG9kWIYbxNg13rAzKb+WEV/GT47dbhMcwfcWcjE36+jgqpHXvczixlHThnOeF8MXeFAQxlkOWlJRjwUqMs62Buz7y9TqwlZIwmCU5ptPcCJl8kypxYySOZk3LCtHzuGEjh4tv6TKi+SOgnuq5m58//XXnPmHg+3ZNSek/RCBvB7jLE9APYDuI+ILgXwSQBPMMYmADyh/w4AdwCY0P/dC+Dzru+1h6SqyTIN9HTnwc5qJV0jX0y+XN+u9YCZ8b5ohdedj9cb7jbJMi72l+Envlo+d8AU3F3U3VWVYfpi1pFThuPzES7d2O1a5m7nSbejWn+ZdI0mZI3UbZyynG2uIyQnGvKXtPzlxdTLxnpw+VhPQydVI3OvuojJ22KzE8ytBziDiVB7FFQZY+cZYz/WbycBHAYwBuBOAA/qD3sQwAf023cC+DLTeB5ALxGNur7nHsGtkFZuB2NIdh3BOF8lcw/5fSCq75K6nsx9vD+Gc0tZKKYawZyprwzHzf4yWaOgWFtzHkyEEfL7cM7F4D6TzEFSVMfFVM7ejT04cmGl5LNqBJ6510NP1L6/TCpXqJ65B7yTZcwNr5ohHvKXfGfeOLuMkN+HXSNd2LuxGxdWcnUfe840dz1zX0W3zMVM5dUPb/vrtf++Ls2diLYCuBrACwBGGGPnAe0EAGBYf9gYAPOIm2l9W0eQ1q1nfgvrWVOyjMUXlIjqHrYwn5QQC/kdBc/xvhgKCsOFleJACi7LmK2QiXAAkaDPleCeqdELxYzPR9jYG8G0i8Gdy1D1B/du5AoqpuZSTb2+1u63/szdamBHQVFxZjFbVWLyUpZptq8Mp7yb6hvTy9gz2oVQwIfLxnoAoO51BjxzD1cbkB1c/YLqktHut1SWUVRWczB6szgO7kSUAPAtAB9jjFW7frUSGytOUUR0LxEdIKIDc3ONL2Rwm5TFoA5O1Fht53yVala3Qlq5Zfj2ei6pF9K1Pe4co/WvyTEzm8yjNxYsWVRFpLUgcCW4VzmZWTHWF3VVcz+tv9d6NHcA2DvmTlFVSw7qz9ytvugn5tOQFBV7Rrtt/9bLRUyGXuyCLMOHZKsqw8Gzy0ZQv7TBYjaXWmqtUAVWt6DKM/fygioAzx0zjoI7EQWhBfZ/ZIz9s755hsst+s9Zffs0gHHTn28CcK78ORlj9zPG9jHG9g0NDTW6/66TtGn3C5hkGZcKqnx7vbKME0kGsF7INLOSKymmcoa6wq60363HLQNourubmvuZxQyIgI29kdoPNrFjKIFQwNf0StXlbME2ObCjN6YF9/LFPIfPawFv92iX7d9Ggs0XDZcykmUAbLbdL4cPyQaAU4sZJPMyrtikBffuSBDbBuOG790p9bhlyj+b+VTes0Zr5SxlJIQCpY3XBo1Vqt7q7k7cMgTgiwAOM8b+3HTXwwDu1m/fDeAh0/YP6a6Z/QCWuXzTCaRy9pl7I7JMrkr7Ab69Pitk7dYDnI29URCVLmSa1ScwlTPkVuZe5yKesd4Y5pJ517KrM4sZjHZHql6uWxH0+7B7Q1dTmftytoCjM0nDWumUnmgQisqMYj7n8Pkkgn7CjqGE7d8W6zaNfX6MMfz0X/0In3rkcMV9y1mtVW2tzpq1iIYCRivk16eXAMDI3AFNEqvXDunELVNeUE3lZfzRw4dw3Z88jn94/lRdr9co2urU0sZr/S1apeokc78ZwP8F4FYielX/914AnwbwbiI6BuDd+u8A8AiAKQDHAfwdgN9yf7e9w2p+KqcRt0yuoICq+J7DdQZ3J03DOKGAD6PdEUybMve5ZL7EKcNxq3kY7yFSjywDAOddGlR95mIGm+qUZDh7dceM1XL4//39SXz1xdNV//6FqQWoDLhpx2Bdr1vsL1MqzRw+v4Kdw122rZ2Bxuo2Zibn0jizmMXTb1VKo8sZCV3hgGX9qR7iIT8kRYWsqDh4dhmhgFZM5Vw21oPpi1nb/jpWOHHLmDP3J4/M4D1//n08+NxJBHyEgy61m6iF1hGy9PtabB62yrIMY+xHjDFijF3BGLtK//cIY2yBMXYbY2xC/7moP54xxu5jjO1gjF3OGDvg6TtwmWqae3EeZD2auzZiz873HKljBqaiMiw6aBpmZpOp9S9jDLPJnGXmPpgIYzEtodDk5WrR5+5MmnDb6366To+7mUs39mA5W6iQiQ6dW8anHz2Czzx2tKrD4dnJBUSCPlyzpbeu1+226S9z5MIK9lSRZDj1HEPlPD+1AED73M4vl75vra9Mc04ZoHiizxQUvHF2GXtGu0tOWJdt5EVV5wHXkSyjZ+6ff3oSH3ngAOLhAL75Gzfi6vE+nFpI1/0+GsFqhW+//pl6PW5PrFAtI5mrrbnX09PdbsQep56s62JGgsqKzYecwFv/an9fQEFhGLHJ3AFYTmZ/9OAF/N0Pphy9XqZOzX2Ti33dcwUFMyv5ujzuZricYl5UwxjDpx45DMY0SataAHrm+Dyu29pftyTE3Shmx8xiWuu5smdDbYmnXmnPzHNTC0b2+8JU6UQqc0+UZjCmMeVlHDy7gsvHSt8T/9zfqMPvzmWZWgVVv4+wkJLw8Xfvwr/9zi24dks/tgzEcGqh9vG2kqusg9SLVeYe8PvQFwu2R0F1PZGW7DP3cEDTN+sqqEqq0dzJinrcMrwAM2gz8NmK8f4oZpI55GXFtDrVQnOv4nX/yyeP4S+fPOboQM9KivGlcsKGngh85E7mzjtMbh5w3nrAzJ4N3fAR8KZJ/336rTk8c3wBv3PrThABjx+esfzb2WQOx2ZTdUsyQLFgafa6H9GLqdWcMpxI0N/QsA7GGF6YWsDtl21AVySAF04slNy/nG2u3S+H98Z589wKUnkZV4yVXtn0xUPY1BetazET965Xy9yDfh/+/j9eh+9+7Bb8zm0TxmO3DsYxm8xXvQLPSDJu/tMn8cCzJx3vkxVa5l6ZjA0kwqtfUF1PMMaqFlSJCNFgfZ0hcwXFst0vJ1KHW8ZYwBSvI7j3xcCYFjytVqdy7IL7QkrLVldysmVWX47TXu6coN+HkW53vO5GN8gGM/doyI8dQwkjO5cVFX/yyGFsG4zjo7dO4JrNfXjyyKzl3z43qQXGm3cO1P26Vm1/33TglOFog6Drz9wn51KYT0m4eecArt/aX5G5uxXc+VXcCye05zcXUzmXbeyxvCpSVYY/+bc3caBszm3eQUEVAN6xa6iiIM0ndFXL3qfm0kjmZXz7lbNVn78ajLGSXu5mBuLe95dZc8H9qSOzuOeBlxqyOuVlbWqSnSwD1N/2127EHidaxyU1D+5DXXXIMqbWv7N65j5i45YBKoP7M5PFbG5qvrZO6WR+ajkbe93xup9p0ONuZq+pDcHXDpzB8dkUfv/23QgFfLh19zDeOLtsXAGZeeb4PLojAezdWBm4amFk7qaC6pELSQx1hR3VVxqVZZ7Tg/n+7QPYv30AU/Np4xjR9qf5jpBAsU/TC1MLCAV8mBipdP9cNtaNE/NpJMs6hP7TS2fwdz88gS+VZdDGIiZ//bNdtw7EAaCq7n58VlvM9vr0ckXzPack8zJklVXIMoBW4/J61N6aCu65goL/5zsH8cSRWbxWp28WMPWVqeJTjobq+yJlC4qtDRLgbhmnmbsuy9RRUDUvZHKUuZdV8H90bA4BXWI5MVc7uGcLsu2CLTvc8rqfWcwgHPCVrL6tl70be3BhJYfTCxl85rGjuH5rP35y7wgA4LY92iLsp8qyd8YYnjm+gBt3DDTkLIkG/Qj6qSRzP3x+Bbs31M7aAX0QdAMF1eenFjDaE8Hm/hhu2N6vbdOza1VfQdnbZC93oFhQPXhuBZeWFVM5e/Vs3jw0ZT6Vx6e/q1k0X5haLJEFnRRU7disZ+4nq2Tuk3MpcA/Eowcv1P0aALCUtl8n0IrOkGsquP/9MyeMIPGDBsZ38Xa/1YJ7LBiw1OpyBQUXLOx82RqZu+Z0cJ65B/QWsU4Z6Yog5PfhzMUMZldy6I4ErEf+Bf3oCgdKMnfGGH54bB637h5G0E+eZe5jfVFcWM413dfl9GIG4/2xhoc5A8Xi3se+9grmUxL+6/v2GM93yUgXxnqjeKIsuJ9ezODsUhY376xfbwc0uc+8SlVWVBybSeFSB3o7wDX3+jJ3rrfv3z4AIsKlo91IhAN4QXfPpCQZKmt+ARNQNCIoKsPlFpIMUHTMmIuqn/q3w8gWFPzq27ZhPpUvOf6aCe7dkSAG4qGamfu2gTj2jHbju40G92xl0zDOQDyM5WyhaXdaNdZMcF9I5fE3T03iXXtGcOV4L354rIHg7jBzt5Jl/ubpSbz7M9+vCNS5glo1c6/nkvr8UhbDXWHbkWtW+HyEsb4ophezmFnJY7jbfuVmudd9ci6N88s5vOOSIWwZiOPEfO2+K1mpujvIirHeKGRVs2k2w5nFLMb7Giumcvhy+B+fXsKdV23ElePF4h8R4bY9w/jRsfmS/7NnjmsBsZFiKkcL7lowmNLbDjjR24H6HFccrrfv1zP2gN+HfVv7DF18WZeIut0oqJpO9pdvsg7uQ11hbOiOGJLYs5Pz+OdXzuLX374Dv3TDZgClbh5JURDwUcMe/C0DMZyct8/cj8+msGM4gfdetgEvn7pombjVwmg9EK/8DPt1r/tFDxcyrZng/tnHjyFbUPDJO3bj7RODePXMUt2NeZwE95jNHNXXp5eQzMl45fRSyfZcQakqU0QCfsgqc1QjmJpPY3uV1Yp2bNJb/2oed3vJYrBsUPaP9BPkLTuHsG0wjhMOMvdsob6CKuDO0A7GWN193K3ojYUw1htFKODDf/7JSyruv3X3MLIFBc9NFWsRz0zOY6Q7jB1D8YZf15y5H67DKQM05nM36+2cG7YN4PhsCvOpvGt9ZYDSBW12mTug6e4Hzy4jL2vy6ub+GD56605sG4xjqCtc4ubJF6oPx67F1oG4beYuKypOLqSxYyiBOy7fAAD43qH6s3e+KMvKLTMY997rviaC+/HZJL7y4mn88g2bsXM4gVsmhqAy4LnJ+bqex5BlGiioHr2gjWgrf01tWLSDYQs1rGyMMUzNpRsKIOP9MUNzH6mWuSdKhwj86Pg8NvfHsHkghu2DcZxcyNSUTup1ywDAJhf6ui9nC0jm5bq7QVrxsXdN4FMfvBybLFw3+7cPIBr048nDmjSjqgzPTS7g5h2DTclBvbGQEVB524Htg85O5I0UVM16O4fr7i+eWDQkBTcWMfHjIRzwYWLY/j3t3diDybkU/uLxY5iaS+O/37kXkaC2APCGbf0lurukNBfctwzEcW45Z/m5nV7MoKAw7BxOYOdwFyaGE3jkDesOKrKi4n997y3LbqJWvdw5fEyml173NRHcP/3dI4gF/fjd2yYAAFdv7kU85McPjtkHd1lRK/qIO5NlAhX93JO5As7pl23PTpZ6hWsuYnLY1W82mUcqLzeUuY/3xXAxU8D55eqZ+5Apcy8oKp6fWsTbJjSpYdtgHJJc+ZmVo53M6tfcgaJPvRF4N0g3gvtd+8bxc9dusrwvEvTjbRODePLILBhjOHIhicW0hJsa1Ns55Zn7zuEux8Gr3uBerrdzLh/rQSzkxwtTC65NYQKgr9DWJK9AlXYBl4/1QGWaxPm+y0fxE5cMG/fdsH0AF1Zyhn1RktWqrQdqsXWwsqkeZ1I3DvBE6o7LNuClk4uWw2y+8KMT+Kunjlu2puCyTLdFslhsQSAyd1uenZzH44dn8Vvv3GmcDYN+H27cMYgfHJ2zXXjzmceP4qZPP4nbP/sD/M3Tx3FmMeNMlglWDvs9ptumdo0k8OqZpZL7s1J1t0zUYXCf1DODak2k7OCOGUVlNTX3ZE5GrqDg1TNLSOVl3LKzGNwB1JRmMpJcd+YeCwXQFws2lbkbfdwb9LjXw7v2DOPsUhZHLiTxrH6l1oi/3Yw5uB+5sII9Dp0yQH1rJYBKvZ0T9Ptw7RZNd3erlzug1X0G4mFcu7mv6uO4/z0RDuC//dSlJfft36btK5dmJLn5zB2wdsxwG+QO/Srj9stGoTLg3w+VLmA7OZ/GZx47CgA4cOpixfMsZSR0RwKWJ7TBuHvTz+zo6OCuLXA4jLHeKD5889aS+96xaxDTF7OWCxUykox/eP40Lh/rQTwcwP989C3c8j+fwp/r/1HVZBmrgiqXZO6+aStkleGlkxeN/cvL1QuqYYfDFng2sb0RWcYU8Kpm7iav+w+PzcNHxSLhtiGnwb3+girQfF/3YubeXEHVCe/UM8onj8zimePz2D4Yx2hPc6/bEw0imZMxl8xrbQcc6u2AJu1JiurYbWSlt3P2bx/AkQtJnNT/n90I7gDwrd+8Ef/3u3dVfcxIdxjvuXQEf/z+vdjQU5qE7BxOYCAeMoqqeUV1PITciq3GQqbK43lyLoXhrrDhStsz2oWtAzF892BRmmGM4b9+5w2E/D588OoxHDy7XPEdvpgplAzpMNMdDSDgI087Q3Z0cP/2K2dx6NwKPnH7JRUB9JYJrUe8lWvm26+cxXK2gP/2U5fiW795E374iXfiE7dfguEurShWddGRRUH16EwK0aAfH7hqDEE/Gdkc7yNdXXN3NiZtai6FWMiPDVUybzvMUkX1giov8uTxo2NzuHxTL3r0y/KhRBiJcKDqpCJFP5k57StTso99MSNAN8KZixn0xYJNt6d1wnB3BFds6sH3Dl3AiycWcVOTWTtQDKIv6m4Vp04ZoP5ZoVZ6O+cGPUN+7PAMIkFf1cSkHrYMxC2HzpshItz/oX34WQtJjIhw/bZ+w82jZe6N71tvLISeaBAnLYL78dkUfteLhAAAFOFJREFUdppqA0SE2y8bxbOTC4aO/s2Xp/HM8QX8/h278b7LR1FQGF4vW1tz0ab1AH9OzesuMndLRnsj+Jmrx/DTV2ysuG/LQAzj/dEK3Z0xhgeeOYm9G7tx3VbtMnG8P4bf+omdePRjb8cTv/cTVQtjsaDmbpFMBdCjM0lMjCQQDwdw9eY+Yyk61+arumUcyzJpbBuM12WD5PTFgsYczuoFVe2+qbk0XpteNiQZQDsYtw3Gq3rd+XuoV5YBtMzs1EK64WHGbjhl6uHW3cN4fXoZaUnBzU1YIDlc2+ZdGuvK3I2JQ7WlGTu9nXPFpl5Egj6cWsi4soDJTfZvH8DZpSzOLGaQb1KWAbTsvfzKnjGGyblUhfz53ss3QFEZHjs8g7lkHv/j3w7juq19+KXrN+OaLVocOXCqsvGaVesBzkA87KilR6N0dHC/accg/vznr7IMeESEWyaG8NzkQslCgWeOL+DYbAofvnlbQ+4Go6e7KRgfnUliYrhL36cBHDy7jOVMoeYUJsD5F3PK4oBzChEZ2bvV6lQOX9n58GvnoKgMt0yUBq1adsh6B3WY2TmcgMpqyz52nFlsvI97I7xrj7ZqlQi4cYd7mfvzUwsYTDhrO8BxmiAA0K2OlXo7JxTw4RpdG3dLknEL7uZ54cQiJFlBuImCKqBdTZRn7nPJPJI5uSRzB7Ri71hvFI8evID//q9vIisp+NOfuRw+H6E/HsL2oThePlmqu2uDOuxPkAOJkLBCNsrbJwaRypd6zx949gQG4iH81BWjDT0nX33JpZmljITZZB679H4ZN+0YhMq0wg//sjXrlskVFJxdyjakt3M29cXQFQ5UXT3KK/g/PDaHWMiPq8sKYNsG4zi7lLXdV2PEXp0rVAEYXyZezLLj1EIaRy6UNphSVIazS9UHSbvN3o3dGOkOY+/GblfsgjyQHptNOerhbqae4M6vDG7cbn+1ccM27WTV44JTxk12DXehNxbE81MLTRdUAS1zP3sxW3IVftzGuKBJMxvw9Fuz+JfXzuGjt+7EzuHi/9O+LX14+fTFkn7/tVomD8RDwgrZKDfuGITfR4bufmohjSeOzOKXb9jcsJZYHLWnOWKOzuhOGd3dcNW4dln77OSCEeyq9fc2vphV5IgT82kw1phThvNz126qKDqXE9T7TKtMuwQu//JsH4qDMdhq45mC9pk0krnvGEqACDg2Uz24f+Kbr+On//JHePzNonPhwkoOBYW1xCnDISL81S9dgz/94BWuPJ85CNQjyQCmtRIOZJnnpxaxsSdStfDMM2Q3FjC5ic9HWvfKEwtN+9wBYPNAHCpDSWOwST25KM/cAU2aUZnmivuNd+wouW/fln4sZQqY0ldxS7KKVF6ukbl72/Z3TQf3nmgQV433Grr7g8+egp8Iv7x/S8PPaUyV0QP30RnNKcPHhoUCPly3tR/PTTrL3KMOCqrcBtlM5n77ZRvw8fdUrrgsh0szb7PwbfNFNVM2DcSMQR0NBPdI0I/N/bGqmbuqMhw6twJFZfjNf3zZaOh0eqH5bpCNcN3Wftvl9PViXuZfb+YedpAgANpw9O8fncONNRZcXTXei1DAVzUwrRY3bB/AmcUszixmm3LLAGbHjCm4z6WRCAcsB9pcPd6H+965A5/7xasrTizX6vW7A7o0U+wrUyVzT4SQkZS6JrvVw5oO7gBwy8QgXp9ewvTFDL5x4Azed8Vo1aJiLWJlmvuxmSQS4QA2mqxbN+0YxFszSWNRjpMVquULo8zwYOp0xWIz8OBerrcDxYUfdro4v1KJNXhVtHMoUTW4n9bXIvyX9+7BZWM9+OhXfoxH3jhf7OPeAhukV/REm8jcA85kmT986BAKioqP3rqz+vMF/fjbX7kG975je1370Qq4m2c5W2g6c99i0fr3+GwKO4bilic/n4/wn39yN3ZbTMfaPhhHfzxk+N2N9g1VTpDc6+5V9r4OgvsQGAN+7+uvIZmX8R9v2trU88XKMve3dKeM+WC4SS+wPfWWtkS9mluGZ135Kl/MybkUxnqjDWXE9bJlII7x/qjlZWlXJIihrrBtA7FmMncA2DmSwNR8yrbPDh9gsX/7AL78ketx5Xgvfvurr+CrL56Gj7S+8J1KOOA3Wv/WexLnx1e1tr+PHjyPRw9dwMfetctYkFaNW3ePNCUDesWe0W506etQmlmhCgCDiRDiIX/JQibeMKxeiAjXbO7Dy3pwr9Z6gGOsUvXIMVPz0yGivyeiWSI6aNrWT0SPEdEx/Wefvp2I6HNEdJyIXieiazzZ6zq4clOPPkJsEVeN91YUCeuFL63P6pdSx2ZS2DVcehm9d6N2APKJ8o56y9TI3JuRZOrhD+7YjW/95k22l+3VHDPZJqyQADAx3IWCwnDKRtN/89wKAj7CzuEEuiJBPPiR63Ht5j68cnoJoz1Ryz7hnURPNFhX2wFOrYLqcraA//ehQ7h0tBu/esu2pvdzNfHrujvQWLtfM0SELaYGYqm8jAsruYZPavu29uHEfBrzqbzReqBqQZX3l/HI6+7k03kAwO1l2z4J4AnG2ASAJ/TfAeAOABP6v3sBfN6d3WycgN9n6Me1CopOMGfu86k8FtJSxWSZgN+HG7YNGMvJqxVvQ35tLqud5q41DGvcBlkvXZGg5YxVzvbBuK3mzk94jbhlgNqOmTfPr2DncML4PBPhAB74yHV4x64h42qpk9m/vR/vuXSk7r+rVZT/s0ePYD6Vx5/97BUdfwIEigXfZoM7oEmNXHOvVkx1wj7d7/7yqYtGR0i7FapAcdC9V7JMzW8hY+wHRLS1bPOdAH5Cv/0ggKcB/L6+/ctMa+jyPBH1EtEoY8y6pVqL+IXrN0OSVdxxWWP2RzPm4M6LqZdY9AG5aceAMUy5mkxBRFX7cc+s5JGWlKbaybrJtsE4FtISljOFCqtcplnN3RTcf3Jv5f1vnlupCOKxUAAPfuT6hl6v3fjsL1zd0N9Vc8u8MLWAr7xwGr92yzbXir+rDbdquhHctwzE8dibM5AVtan+TYDWGyfk9+HlUxcNOaZaQXWoK4xf2b/ZaO3hNo2lWMAID9iMsfNExNu3jQE4Y3rctL5tVYP7O3YN4R27hlx5LmMRk6QYtj3ulDFjXpJey3YZCfpss64pwynTHvqn0UBsIY2rYqVT7JvV3Hlh+ph+0jSzkMrjwkrOGKYhKGJXUM0VFPzBP7+B8f5ozb4uncTejd3YvaHL8RjCamwdiKGgMJxfzuH4bAoBHxkDtOslEvTj8k09OHByEddt7Uco4KvZeuR/fODyRne9Jm5fo1kJtZbdjIjoXiI6QEQH5ubqn5q0WvD/LJ65d0cClv1adg13GZddkRoZRjToR1aylmWazSbcZrvRQKxSOslKCnyEpixqO4YTxkISM4fPawHf6ei59YRdf6LPPn4MU/NpfOqDl9c9+rCdCfh9ePRjb8cHr7Zuy1wPxe6QaUzOpbBlINaUdHXtlj4cPLuCCys59MWCTfX4b5ZG38UMEY0CgP6TD5WcBjBuetwmAOesnoAxdj9jbB9jbN/QkDtZdSsI+H0I+X3IFrTgfsmGLlvb1P4dAwj5fVV7WAPVZ2BOzqURD/ktfberwXh/DD6yHpbN56c2c0BPDHfh+GyqZKUfALx5XmvKVK9NcD0QDpQW5QuKij96+BD+9vuTuOvaTUYTPUElW02tf8sbhjXCtVv6ICkqnjk+v+rrBBoN7g8DuFu/fTeAh0zbP6S7ZvYDWF5tvd0LtM6QMo7OpDBhIclwfvvWnfij91uIx2WEg35bK+TkXArbhxKrmgGYCQf82NQXs2wgli3ITXcRnBhJIFdQK3q7v3luBRt7IlULVOsVn48QCmjS3mJawoe++CIeePYk7nnbNvzpz3h32b8WGO4KIxL0YXI2hVMLmaavkK/Vi6rzKcmVQSfNUPNajYi+Cq14OkhE0wD+EMCnAXydiO4BcBrAXfrDHwHwXgDHAWQAfNiDfV51Yro3djlbwK4qZ/rdG7otFzyUU20G5tRcGvu2NmffdBs7O2QjI/bKmTAVVc2tit88vyL09ipEAj68eW4F7/+rH2E2mcf/uutK22lSgiI+H2FLfxw/ODoHWWVNZ+6DibDx/VjtzN2JW+YXbe66zeKxDMB9ze5UuxMN+fHatNaMbJcLRR07t0xW0hqG/fzQuMVfrR7bBuN46aQ2z5JfUbx1IYl/PzTT9EQi/uU6NpvEO3drdfpcQcHkXBq3793Q3I6vYSJBP354TBvU/fVfvxFXjffW/iMBAK09+L/rvYrcqG1du0Xzu7vRUK4ZOt/0ugrEQn5jebGVU6Ze7NwyPDtu1QImp+wYiiMjKZjV562u5Ar4jX94GYlIAJ/6YHMyQG8shMFEuKSB2NGZJBSVicy9ClsGYrh2Sx/+5aNvE4G9TraaVuw2sjq1HO53r2aDbAVrp4TeQmL6KtX+eKiuvtt22M3AbDenDGebvjx+ci6FoUQYH//aazizmMFX791fdUarUybKHDOHzmltBy4dXRs+bS/4yq/tR8BHbVOb6SS49XFDd6Tq/GSncBm1f5XrQyK4NwD3ce8acSfoalbIysx9ai4NIjjqBdJKzPNUXzm9hMcPz+APf/pSXLfVegBEvewcTuA7r5w1ZJ83z62gKxzApr7O7R3jNWth5elqwR0zzertnB1DCfx/d12Jd1yyui4lEdwbIGYE9+YlGUB3y1jIMrxhmFtzLN1itDuCcMCHbxyYxmvTS7jzqo1NN2QzMzGSQDIvY2Yljw09Ebx5fgV7RrsbGjEoENSCt4p2K7gTkeUc2FYjTvcNwDP3ajbIehjtiWA+JeHbr0yXbJ+aT7XNylQzPp82T/XVM0u4ZKQLf/ozl7sqB5jbEKgqw2HhlBF4yMbeKN53xSjuuGxtFexF5t4APHO/xKXgfu/bt+O5yQX8p2+8jmjQj9svG9UbhqVdkzrc5pINXTi7lMXf/sq1rq9+NDtmxvqiyEiKWJkq8Ay/j/DXv7TqDWxdR2TuDcBbELiluUeCfnzh7n24clMPfvurr+CpI7O4sJJDRlLaMnMHgD9+/148+rG3lzgN3GIoEUZPNIhjsym8yYupInMXCOpCZO4NcMflowgH/K76WOPhAL704evxy194Hr/+Dy/j1/S+2+3SDbKc3lgIvR5NtSMizTEzm0JfLGj0cBcIBM4RmXsDXLO5D//pJ2vPI62XnmgQX/7IDdg6EMNfPzUJoP1skK1iYkQL7m+eK+3hLhAInCGCe5vRHw/hH371BmwbjKMnGrTsOLke2DGUwGJawksnLwq9XSBoACHLtCHDXRH882/ehJlkbt0uSuFOpFReFnq7QNAAIri3KX3x0LrugDhh0thF5i4Q1I+QZQRtyWhPBHHdcip6uAsE9SMyd0FbQqQ5ZOaS+XV9BSMQNIoI7oK25bdvnUBakld7NwSCjkQEd0Hb8q5LR1Z7FwSCjkVo7gKBQLAGEcFdIBAI1iAiuAsEAsEaRAR3gUAgWIN4EtyJ6HYieouIjhPRJ714DYFAIBDY43pwJyI/gL8GcAeASwH8IhFd6vbrCAQCgcAeLzL36wEcZ4xNMcYkAP8E4E4PXkcgEAgENngR3McAnDH9Pq1vK4GI7iWiA0R0YG5uzoPdEAgEgvWLF4uYrNoYsooNjN0P4H4AIKI5IjrV4OsNAphv8G/bCfE+2gvxPtoL8T6s2WJ3hxfBfRrAuOn3TQDOVfsDxthQoy9GRAcYY/sa/ft2QbyP9kK8j/ZCvI/68UKWeQnABBFtI6IQgF8A8LAHryMQCAQCG1zP3BljMhF9FMD3APgB/D1j7JDbryMQCAQCezxpHMYYewTAI148twX3t+h1vEa8j/ZCvI/2QryPOiHGKmqdAoFAIOhwRPsBgUAgWIOI4C4QCARrkI4O7p3aw4aI/p6IZonooGlbPxE9RkTH9J99q7mPTiCicSJ6iogOE9EhIvpdfXvHvBciihDRi0T0mv4e/ljfvo2IXtDfw9d051fbQ0R+InqFiP5V/73j3gcRnSSiN4joVSI6oG/rmGOKQ0S9RPRNIjqif0dubOX76Njg3uE9bB4AcHvZtk8CeIIxNgHgCf33dkcG8HuMsT0A9gO4T/8/6KT3kgdwK2PsSgBXAbidiPYD+DMAn9Hfw0UA96ziPtbD7wI4bPq9U9/HOxljV5k84Z10THH+AsCjjLHdAK6E9v/SuvfBGOvIfwBuBPA90+9/AOAPVnu/6tj/rQAOmn5/C8CofnsUwFurvY8NvKeHALy7U98LgBiAHwO4AdoqwoC+veRYa9d/0BYMPgHgVgD/Cm21eCe+j5MABsu2ddQxBaAbwAnoppXVeB8dm7nDYQ+bDmKEMXYeAPSfw6u8P3VBRFsBXA3gBXTYe9GljFcBzAJ4DMAkgCXGGJ/O3SnH1mcBfAKAqv8+gM58HwzAvxPRy0R0r76to44pANsBzAH4ki6TfYGI4mjh++jk4O6oh43Ae4goAeBbAD7GGFtZ7f2pF8aYwhi7Clrmez2APVYPa+1e1QcR/RSAWcbYy+bNFg9t6/ehczNj7Bpokut9RPT21d6hBggAuAbA5xljVwNIo8VSUicH97p72LQ5M0Q0CgD6z9lV3h9HEFEQWmD/R8bYP+ubO/K9MMaWADwNrX7Q+/+3c/cqDQRRGIbfU4mIoIKdhdjYib0WomKRwsrOIoVXIYKX4B1YWygoYqvWiuAPUUEtBIOKt2BxLOYspBEMQjYzfA8sO9mkmA9mzyYzZMys+pNfDmNrDlg1s1fSNtuLpG/yueXA3d/j/AUckh64uY2pNtB294t4fUAq9j3LkXNxL20Pm2OgGe0maf66r5mZAbvAo7vvdLyVTRYzGzezkWgPAsukha9zYC0+1tcZANx9090n3H2SdC+cufs6meUwsyEzG67awArQIqMxBeDun8CbmU3HpSXggV7mqHvh4Z+LFg3giTRHulV3f7ro9x7wAXyTnvAbpPnRU+A5zmN19/MPOeZJP/PvgJs4GjllAWaA68jQArbj+hRwCbwA+8BA3X3tItMCcJJjjujvbRz31X2d05jqyDILXMXYOgJGe5lD2w+IiBQo52kZERH5hYq7iEiBVNxFRAqk4i4iUiAVdxGRAqm4i4gUSMVdRKRAP67S7Fzt1h7TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of the size of recipes in chars in the dataset is: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of length of words in the dataset is:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZwcVb338c9P1styZcmI7AHB8KACxnkCiHiRzUBwx0dQryhwI1z1IuqDRB5E5dGLIIuIElAgIGGHIGsAISQkhCQz2fdMkkkymSQz2XeSyfzuH10909NT3dP7UvN9v17zmqpTp+qcOlX96+rqOqfN3RERkej6QLkrICIixaVALyIScQr0IiIRp0AvIhJxCvQiIhG3e7krEKZPnz7et2/fcldDRKRq1NfXr3b3mrBlFRno+/btS11dXbmrISJSNcxsSaplunUjIhJxCvQiIhGnQC8iEnEK9CIiEadALyIScQr0IiIRp0AvIhJxCvQivVjj6i2MXbC63NWQIqvIDlMiUhpn/eFtABpvGVTeikhR6YpeRCTiFOhFRCKux1s3ZvYgcBHQ4u4fD9KeBPoFWQ4A1rv7KSHrNgKbgF1Am7vXFqjeIiKSoUzu0Q8D7gEeiSe4+zfi02Z2O7Ahzfqfc3d92yMiUiY9Bnp3H2NmfcOWmZkB/wc4u7DVEhGRQsn3Hv2ZwCp3X5BiuQOvm1m9mQ1OtyEzG2xmdWZW19ramme1REQkLt9AfynweJrlZ7h7f+AC4Adm9tlUGd39fnevdffamprQsfNFRCQHOQd6M9sd+CrwZKo87t4c/G8BRgADci1PRERyk88V/bnAXHdvCltoZvua2f7xaeB8YGYe5YmISA56DPRm9jgwHuhnZk1mdkWw6BKSbtuY2WFm9kowewgw1symAROBl919ZOGqLiIimcjkqZtLU6R/NyStGbgwmF4EnJxn/UREJE/qGSsiEnEK9CIiEadALyIScQr0IiIRp0AvIhJxCvQiIhGnQC8iEnEK9CIiEadALyIScQr0IiIRp0AvIhJxCvQiIhGnQC8iEnEK9CIiEadALyIScQr0IiIRp0AvIhJxCvQiIhGnQC8iEnEK9CIiEddjoDezB82sxcxmJqT9ysyWm9nU4O/CFOsONLN5ZtZgZtcXsuIiIpKZTK7ohwEDQ9LvdPdTgr9Xkhea2W7An4ELgBOBS83sxHwqKyIi2esx0Lv7GGBtDtseADS4+yJ33wE8AXwph+2IiKS0ZvP7/OXtBty93FWpWPnco/+hmU0Pbu0cGLL8cGBZwnxTkBbKzAabWZ2Z1bW2tuZRLRHpTX769DRuHTmPKcvWl7sqFSvXQH8v8BHgFGAFcHtIHgtJS/mW6+73u3utu9fW1NTkWC0R6W02b28DYFe7ruhTySnQu/sqd9/l7u3AX4ndpknWBByZMH8E0JxLeSIikrucAr2ZHZow+xVgZki2ScDxZnaMme0JXAK8kEt5IiKSu917ymBmjwNnAX3MrAm4CTjLzE4hdiumEfh+kPcw4G/ufqG7t5nZD4HXgN2AB919VlH2QkREUuox0Lv7pSHJD6TI2wxcmDD/CtDt0UsRESkd9YwVkaqmr2B7pkAvIpEQ9pifxCjQi4hEnAK9iEjEKdCLiEScAr2ISMQp0ItIVdNgZj1ToBeRqhYP86bHblJSoBeRiFCkT0WBXkQk4hToRUQiToFeRCTiFOhFRCJOgV5EqpqeruyZAr2IRIIer0xNgV5EJOJ6daBfsGoTaza/X+5qZKxl03YWtm4udzUKbkdbO/VL1pWsvPZ254Gxi9m6I/aj0i0bt7Mow3Zt2ZR53jBTl61n+85dWa/XtG4ry9ZuzbncQpm5fAOb328rebnt7c6kxrUlLzcqenWgP+/OMZx355hyVyNjA377JufcPrrc1Si4370yh6/d+y7zV20qSXl3v7WAm1+azUm/eh2AAb97k7MzbNcBv808b7KVG7bz5T+P4/pnp2e97md+P4ozbx2VU7mFsqOtnYv+NJb/eLiu5GXfN2YRXx86nnENq0tedhT06kAPsHbLjnJXodebvWIjULpjMas5Vl5be2m/xdv8/k4AZizfUNJyC6U9+NZz8tLSffqKW9ASuwhYsWF7ycuOgl4f6EWkuumhm571GOjN7EEzazGzmQlpt5nZXDObbmYjzOyAFOs2mtkMM5tqZqX/vCcivYYeukktkyv6YcDApLQ3gI+7+0nAfGBImvU/5+6nuHttblUUiRZdgRaYHqTvUY+B3t3HAGuT0l539/hX7+8BRxShbiIRo2vOYjI9SJ9SIe7RXw68mmKZA6+bWb2ZDU63ETMbbGZ1ZlbX2tpagGqJSCGV9cJZF+15ySvQm9kNQBswPEWWM9y9P3AB8AMz+2yqbbn7/e5e6+61NTU1+VRLRIqonBfOumbPTc6B3swuAy4CvuUpfsvL3ZuD/y3ACGBAruWJRIauTgtKzdmznAK9mQ0Efg580d1Du+uZ2b5mtn98GjgfmBmWV6Q30C3k4lLzppbJ45WPA+OBfmbWZGZXAPcA+wNvBI9ODg3yHmZmrwSrHgKMNbNpwETgZXcfWZS9EBGRlDJ56uZSdz/U3fdw9yPc/QF3P87djwwemzzF3a8K8ja7+4XB9CJ3Pzn4+5i7/7bYO5ONJWu2ZL3OYxOWMnLmirR5mtZt5YYRM2jb1Z5r1fIyYkoTI6Y0ZZx/+IQljJy5sog1qmyrE8Y6amiJjWHz5KSlvDS9ueBlrd8a6/m7LYexbsKccctb/PrFWWnz7Gp3/t/zM3ocJ2fj9p1c98w0tuQwjs2wcYt5a+4qABpXb+Gmf8ykvUi9jl+btZLhE5Z0SZvelHlP43VbdnDdM9PYvnMXO9raGfLcdFZtjH5v217bM/Y/h0/Oep1fjJjBVY+mX++nT01j+ISlTGosfTdxgGufnMa1T07LOP8NI2Zy1aP1RaxRZfvty3M6pi8fNgmAnz87gx8+NqXgZd35xgKgcN34l6/fxkPjGtPmqV+yjkffW8pPnpqaNt/QtxfyVF0Tw95NvT1PcTf8Vy/O5vJhsf6QVw+fzMPjlzBn5ca05WUrXvLrs1dxw4jc7wDf/sY8nqpr4un6Jt6a28LjE5dx4/PRv6PcawN9sR4Vi29W92OlmmTzcrA0d8Pjz2Wky1NOvbVvVa8N9CJSPSrzbaN6KNBLr5N4VZfiyWBJI9UtnHLL6lN0LzvuCvQiJVLtt/Mq9XZMNqr9GORKgV7Kr3ddXFWtbK7kCx1QdYrkR4FeKkY5LrYSA0hvvdqD7Nq+Uq/ss6lXb3vjUKAvkl52C7Agyt1kUT5mUd63bHR9M+g9jaJAX2CVea1T4dRoRVPqTynV+IbSGz7JKdBLL1SF0ajKVHrwrMY3pHwo0BP+iN2udqdtV3vosrZd7Tl18W5P2Gaq9Xe1e5cy43lTpe3KsB7unvWwDMnlZrNeT+2Tru672jv3L76dsDZL1Y5h201s1/Yuj1emrWZHGWFtkeoYhO1/pscp1zYPO29iaZmtn5wtsW3j522m+xBbv+t8qv1qDznWuxLKzeYcj6+7K2F78fmO8rzzfEqsTjxf4ms+m3KzkVjHUtm9ZCVVmNkrOrtoX/rX93hi8Oldln/kF7Gx2S4/4xh++YUTuyw77obY76w03jIoqzKPDbb5L3vsxradu7qtv3bLDvrf/AY3XnQiV3zmGAC+cf97TFy8liuDeYDLHprEmPmtDLngBP771blM++X5fHCfPdKWfcyQWNmvX/tZPnrI/hnV9yM3vEK/Q/Zn5I9T/oxAqLNvf5tVG99nzs3Jv0DZ6clJy7j+uRmMH3J2l/QN23Zy8q9fB+CM4w5mXMMaGm8ZxMVDx1O/ZF2XNrv60cmMnLWyS9qs5g0MunssD363lrNPOASA7Tt3ccKNI/nR2cfx0/P78dbcltA6hY1Bc80TU3lhWmzcm3P/1yFdlsWPJ8B7Q87hwx/cG4Azbx3F5vfbmHbT+UBsDJ1z7xidsi2St/m5fjU89L3MR/RetXE7p/7uTX73lU/wzVOPAuDe0Qu5deQ89tsrs5f4vW8vBGBHW+xi4LpnpvN0fRONtwzqsp8AOzK4YPjW3yYw+cbzOuaP/cUr/NtHa3j48q77dcbv32Lbzl2cdMQBjJnfyrjrz+aMW97i91/7BD9/dgYfsNgb81n9wn+jYnPC2DxXPVrP8vXbQvONH3I2m7a3MXzCUiA2bENcQ8vmjtd73B8vOYVrnpjK2z87i7599u1xfzNV17iWi4eOB+g4H0tBV/TAe4vWplw27N3FBS8v1aBWzcFJ+mx956BkExevDerR2JE2Zn7sF7ieqlsGQOvmzMdOyWYAKHeYu3JTxvnjGtds7XHgruenLgdg8equg8slDjI2rmFNx3T9ku5jB42c1X0wtslL1wPw5pzOYB4fqCv+Ik9l47ad3dLiQR7gn3NWpVy3MWGQvOXrt7EhYVszl2fe5gCj5mX3C2vxNoy3KcATE2PnxuYsByl7Pwj0T9enHhgv3ZVu/BHMtVt2dFs2en73/VqxYTvrt+7sOKcXrIqdbyOmxPYlXtTKFOMDrUsoJ1WQh1gbTV22PnTZwtbuAxy+PD02eGEu53867y7sPKd7Oh8LSYFeerVedqtWeikF+iKp1G7iFafIg8t1SevhnmixjlglfDFZqrOxUM/Y97YvS4tNgb7AivWijtp5X6xON2FbtUqItCUWtQuN3ngMC0mBvgdRO8EqfW9KXT8NatZVvqd7vm8wUT8a5Xr9KdD3INtAoLhRuXo6NJX+JlgKlXr+6g05Pwr0RVKp44FUmmK9fBPjQimORLo4VI5Phbmef1G75dNFhHetJwr0UhbFin0Ru9OWs2oP2AWvfc4bLGxNEs/PUn5KySjQm9mDZtZiZjMT0g4yszfMbEHw/8AU614W5FlgZpcVquKlErV79NJVKV5qvekMyjt2Zbm+Lhgyk+kV/TAguZvj9cCb7n488GYw34WZHQTcBJwKDABuSvWGEDX5XFFlu2Y1374sXt2ruFFy1Qt3uZqV8iIyo0Dv7mOA5O6jXwIeDqYfBr4csurngTfcfa27rwPeoPsbRlFMalxL4+otzF25kRlJvUG37ujeW/CtuZ29Ht+Y3Tm9q91paEndO27Fhm2MXbC6Y35C0JP13YRenTOaNjCruXvvyL+Pb+TVGSs65tMd97CPeck9+prWbe0yv6vdGTGlKeW4M4n7/OK0Zh6bsJSdu9ppXL2FSY2dh3vZ2q3d1p3dvLFbj88x81uZ3tTZ+/Dml2Yzc/kGXpzWTMvG7fx9fCPvLIj1gNy0PXYMho5e2NH7tz1F1H89oQfsiClNPDFxacpejmNCel/Gt9q2q/v4IvEekGHCjllcWC/PMO8tWsP/f3l2t/SfPDWVt+e1sGztVl6Y1tytXlOWrqOhZRPzVm7ipn90fJDmpenNnHfH6K7nTfB/zsqN3PXP+Yye38qytV17iba789W/jOOTv3mdBas20R6cG8nuG72IuSs7hwd5t2F1tzxAx3F8aXpzl/QFLZs7ppeu2coJN77K+22dvaTjvWr/OXtVl16tyZJ7Qof1UB02bnFHD+CeTM+yd3KilRu2886CVt5btCb0tQCd+9PQspnJSzvr3rx+G+MaVtOyaTs/enxKl/N27ZYdjJrXwsPvNjJ6fivjUrR1IeQz1s0h7r4CwN1XmNmHQvIcDiQeiaYgrRszGwwMBjjqqKPyqFbM14PxJOKSx0hJdvmwOubePJCN23fyH4/UdVl27h1jePtnZ4WWM/Cud9iwbWe3cWvuGdXAzz4fG8fiC/eMDV33xn/MAugYTyPd1W0m4yudddvbXeYfGd/Ir1+czbYd3ccm2b5zF5cP69zPHz0+BYiNm/LHNxd0yXvmraO67d+Fd78DdG3X7zw4sUueB8Yu5oGx3YeQaLxlEDOCF97YhJP7yUnLuOac47vlH/z3+o7pa5+c1m15otdmxd685iUEhleCoLj5/TZeTBPYkw26O/y4AVyWtK+pXHL/e6Hpz01eznOTO4cs6LPvnnz6uD4d81/5y7uh6/3wsdhxunp493N40/Y27vrngm7pAFOWdgaY8+4cw81f/jg3Pj8zNO/Au97pmP7m3yaE5vn3BybSeMugjvqE+extowA45/bOcX4eGreYr/U/gisfqaP26O4f7uNvCpkMKJY4Xk1Pbnl1Lrd+7aSM8ye66E/vsHpz55tS8mthw9adXPlIHf2POqBjCI54nnPvGM3WHamHA/neQ5O6zGc7flamiv1lbNg1augRdPf73b3W3WtrasIHMCqURas3h6a3u3cM6pQs1cHaEDI+Sra2t3Xddq4f6NqSXhzxcWPWbukcPyb+qSHV1XPLpvdD00th7ZYdBfs4m3i81m/dETpdSPl++blxe3Zj0uRrzebSHeemdZ2fLlo3v8/OYFC0JSFXx1kOsFoSiUE+THyQt6Uh+5MuyJdSPoF+lZkdChD8DxsSsAk4MmH+CKA5JJ8UQW73v3WjtzzU7sVW7U8i5SOfQP8CEH+K5jLgHyF5XgPON7MDgy9hzw/SKpJhkXzKJor7lCu1RIz6efQumT5e+TgwHuhnZk1mdgVwC3CemS0AzgvmMbNaM/sbgLuvBW4GJgV/vwnSRIqqS4epDN/oyvl+mM/TR9V2nVpN9a3mJ9oSZfRlrLtfmmLROSF564ArE+YfBB7MqXYlZladV3yFDFBRObFTStNY+ex7tV0hV8KHvAqoQkrVdjx7op6xFSDywbXMNE6K9HYK9Ekq4UqnUBTeukt3eMt666bE5UXoNM9Y1K7Ss6FAn6FSBoHe1DM2KnrzEx3ZSj8AXOnqkU42x7Majn2vDPTp3tnL+a5fipM8XkalXt0Uo1bV8NRRft8P5LBO5TdJRciunSq3UXtloE/FrDwvgEp60UX900EltXU5lfPNL13RxaxVNVx5F0s+QyBUpJ8/M53jD9mvW/oX7xlL/6MOZNi7jSnX3bgtde/EC/74TsplEOsG/e0HunYX/86DE0PHXkk28K53GPrtT7HX7rH33TkrNvawRlfn3TmGcdef3SXtqr/XMzIYI+a21+Z1pP91zGKO6bMfVz7ctet1j2XcMbpjHJNpN53fkf6LETN4bMJS+h91QMbb6nv9y6HpU5auTzlcRDoX/PGdbm02b9WmjnL+bzAUBcCwcY0pt7N9ZztDnpuRdfkQG9vottfmce25H+1I+9TNb2S8vuMp26Un30gxzEKxJdc3k/rfN3oR941eBIT3ws40FA+6O/3rMV/xoTSuChkuJdFtr81lVnPs3Fud0Nt44F1jePqq04tXwSxFLtA/WRc+yNH0pg1Mb0o/sNG4htV8+iMH51Tuc1OaOsZvicskyMdd9Wg9gz5xaE5lAzw2YUmX+ZEJA4Elmr1iI795cVaP3bqTJQ5WlTiI22MTlgJ0jPGRj83v5zYMQDZvjIn7EebxiUtzqsM9oxoAuOyhzjFw1qQZtCtZJmO7SKd4cC23P49aGJo+d+Umxi9cE7qsHHTrpkCicsujN3+8LYSonAcSLQr0yXK8SajXt1QTfVfRuyjQF0hUOuVEZDekSun8Kw4FesmargarX6U+Xqtbh8WhQJ8gr5//0/kpUtFK/RqtpJCgQJ+krFc6lXmRJSJVToE+IrJ5g8q3s4zejwpPnwhjotQOlfQ6UaBPkmsMLMS9xUo4MSL0OpM0KvV7liidf5W0Lwr0BVKIK5FKOjGktPQlpBRTpAL98vXbes6URvP67bw9L/PerA0JvSynNeXfMzSxh+fclRtpz6K35MLW9D0+M9WcQRtOWFxdPxKW+OPUlaq9xD+KXddYmcdw0/adRdv2zgL1Pp6waA0LVm1iR1v6g1ZJ551V4vPftbW1XldXl/V6uY4VUqn+6+zjuPuthoJv91NHH0j9knUF367k7rgP7dflwkF6p8ZbBuW8rpnVu3tt2LJIXdFHzagsPl1IdVOQl2JSoK9gum8rIoWQc6A3s35mNjXhb6OZ/Tgpz1lmtiEhzy/zr3LvUay7ahX6wIWIFEnOwxS7+zzgFAAz2w1YDowIyfqOu1+UazkiIpKfQt26OQdY6O5LeswpZVepz1CLSHEUKtBfAjyeYtnpZjbNzF41s4+l2oCZDTazOjOra23Vl5AQrV6CIlI+eQd6M9sT+CLwdMjiycDR7n4y8Cfg+VTbcff73b3W3WtramryrVYkKM6LSCEU4or+AmCyu69KXuDuG919czD9CrCHmfUpQJkiIpKhQgT6S0lx28bMPmzBCFpmNiAor3J+SFFEpBfI68fBzWwf4Dzg+wlpVwG4+1DgYuBqM2sDtgGXeCV2xa1QxWqqSv3RCREpjrwCvbtvBQ5OShuaMH0PcE8+ZfRmc1duKsp2J1boOCcivV39knV86ugDC75d9YwVEakQX7v33aJsV4FeRCTiFOhFRCJOgV5EJOIU6EVEIk6BXkQk4hToRUQiToFeRCTiFOhFRCJOgV5EJOIU6EVEIk6BXkQk4hToRUQiToFeRCTiFOhFRCJOgV5EJOIU6EVEIk6BXkQk4hToRUQiToFeRCTi8g70ZtZoZjPMbKqZ1YUsNzO728wazGy6mfXPt0wREcnc7gXazufcfXWKZRcAxwd/pwL3Bv9FRKQESnHr5kvAIx7zHnCAmR1agnJFRITCBHoHXjezejMbHLL8cGBZwnxTkNaFmQ02szozq2ttbS1AtUREBAoT6M9w9/7EbtH8wMw+m7TcQtbxbgnu97t7rbvX1tTUFKBaIiICBQj07t4c/G8BRgADkrI0AUcmzB8BNOdbroiIZCavQG9m+5rZ/vFp4HxgZlK2F4DvBE/fnAZscPcV+ZQrIiKZy/epm0OAEWYW39Zj7j7SzK4CcPehwCvAhUADsBX4Xp5liohIFvIK9O6+CDg5JH1owrQDP8inHBERyZ16xoqIRJwCvYhIxCnQi4hEnAK9iEjEKdCLiEScAr2ISMQp0IuIRJwCvYhIxCnQi4hEnAK9iEjEKdCLiEScAr2ISMQp0IuIRJwCvYhIxCnQi4hEnAK9iEjEKdCLiEScAr2ISMQp0IuIRJwCvYhIxOUc6M3sSDMbZWZzzGyWmV0TkucsM9tgZlODv1/mV10REcnW7nms2wb81N0nm9n+QL2ZveHus5PyvePuF+VRjoiI5CHnK3p3X+Huk4PpTcAc4PBCVUxERAqjIPfozawv8ElgQsji081smpm9amYfS7ONwWZWZ2Z1ra2thaiWiIhQgEBvZvsBzwI/dveNSYsnA0e7+8nAn4DnU23H3e9391p3r62pqcm3WiIiEsgr0JvZHsSC/HB3fy55ubtvdPfNwfQrwB5m1iefMkVEJDv5PHVjwAPAHHe/I0WeDwf5MLMBQXlrci1TRESyl89TN2cA/w7MMLOpQdovgKMA3H0ocDFwtZm1AduAS9zd8yhTRESylHOgd/exgPWQ5x7gnlzLEBGR/KlnrIhIxCnQi1SZow7ap9xVSOugffcsdxUkiQK9SJVx9DWXZEeBXkQk4hToRaqMnluTbCnQi4hEnAK9iEjEKdCLSEGl7VwjZaFAL1JldI9esqVALyIScQr0IlJQpns3FUeBXqTK7L1H6pdtJQTZvffYrdxVkCSRCvT/dc7xWa/zscP+Naeybv5S549lfeLwD9L/qANS5v3CyYdxTYq6HbDPHlmXvcduub2a99+76xh2119wAgftuyf3fPOTfKAAAeKED++f83qJwevH53a21Z67ZXaK7rl7eL58u+N//9+O7TF4fvu0ozLaVp/9Mq/L8CtPDU3/zHF9GPa9Ad3S99lzN64b2I8JQ87JuIxM/PdXPwHAgL4HhS6v2X8vzjju4C5pj15xasd6nzmu+89P/O++B3ZLSzx3zjy+DwcnHLdczvczj+/DrRefxHUD+3WkPXBZbWjexHNn0EmH8oevn9ytjhd8/MNZ1yGZGZxyZOo4UUxWiaMG19bWel1dXbmrISJSNcys3t1D380idUUvIiLdKdCLiEScAr2ISMQp0IuIRJwCvYhIxCnQi4hEnAK9iEjEKdCLiERcRXaYMrNWYEmOq/cBVhewOqWkupeH6l4+1Vz/Sqv70e5eE7agIgN9PsysLlXvsEqnupeH6l4+1Vz/aqq7bt2IiEScAr2ISMRFMdDfX+4K5EF1Lw/VvXyquf5VU/fI3aMXEZGuonhFLyIiCRToRUQiLjKB3swGmtk8M2sws+vLXR8AMzvSzEaZ2Rwzm2Vm1wTpB5nZG2a2IPh/YJBuZnZ3sA/Tzax/wrYuC/IvMLPLSrgPu5nZFDN7KZg/xswmBPV40sz2DNL3CuYbguV9E7YxJEifZ2afL1G9DzCzZ8xsbtD+p1dZu18bnDMzzexxM9u7UtvezB40sxYzm5mQVrC2NrNPmdmMYJ27zQr3g4kp6n5bcN5MN7MRZnZAwrLQ9kwVf1Ids5Jz96r/A3YDFgLHAnsC04ATK6BehwL9g+n9gfnAicCtwPVB+vXA74PpC4FXAQNOAyYE6QcBi4L/BwbTB5ZoH34CPAa8FMw/BVwSTA8Frg6m/xMYGkxfAjwZTJ8YHI+9gGOC47RbCer9MHBlML0ncEC1tDtwOLAY+JeENv9upbY98FmgPzAzIa1gbQ1MBE4P1nkVuKDIdT8f2D2Y/n1C3UPbkzTxJ9UxK/VfyQssyk7EToLXEuaHAEPKXa+Qev4DOA+YBxwapB0KzAum7wMuTcg/L1h+KXBfQnqXfEWs7xHAm8DZwEvBC211wougo92B14DTg+ndg3yWfCwS8xWx3v9KLFBaUnq1tPvhwLIg6O0etP3nK7ntgb5JwbIgbR0sm5uQ3iVfMeqetOwrwPBgOrQ9SRF/0r1eSv0XlVs38RdGXFOQVjGCj9OfBCYAh7j7CoDg/4eCbKn2o1z7dxdwHdAezB8MrHf3tpB6dNQxWL4hyF+Ouh8LtAIPBbed/mZm+1Il7e7uy4E/AEuBFcTasp7qaPu4QrX14cF0cnqpXE7sUwRkX/d0r5eSikqgD7tnVzHPjZrZfsCzwI/dfWO6rCFpnia9aMzsIqDF3esTk9PUo2LqTuyqtj9wr7t/EthC7PZBKpVUd4L72V8idnvgMGBf4II0damo+tLJ1WcAAAIpSURBVPcg27qWbR/M7AagDRgeT0pRl4qre7KoBPom4MiE+SOA5jLVpQsz24NYkB/u7s8FyavM7NBg+aFAS5Ceaj/KsX9nAF80s0bgCWK3b+4CDjCz3UPq0VHHYPkHgbVlqnsT0OTuE4L5Z4gF/mpod4BzgcXu3uruO4HngE9THW0fV6i2bgqmk9OLKvgy+CLgWx7cd+mhjmHpq0l9zEoqKoF+EnB88A33nsS+kHqhzHUieDrgAWCOu9+RsOgFIP5UwWXE7t3H078TPJlwGrAh+Nj7GnC+mR0YXO2dH6QVjbsPcfcj3L0vsfZ8y92/BYwCLk5R9/g+XRzk9yD9kuDJkGOA44l9uVbMuq8ElplZvyDpHGA2VdDugaXAaWa2T3AOxetf8W2foCBtHSzbZGanBW3xnYRtFYWZDQR+DnzR3bcm7VNYe4bGn+AYpDpmpVWOLwaK8Ufs2/z5xL79vqHc9Qnq9BliH9WmA1ODvwuJ3bt7E1gQ/D8oyG/An4N9mAHUJmzrcqAh+PteiffjLDqfujmW2MndADwN7BWk7x3MNwTLj01Y/4Zgn+ZRwCcmeqjzKUBd0PbPE3uSo2raHfg1MBeYCfyd2JMeFdn2wOPEvkvYSezq9opCtjVQG7TDQuAekr5kL0LdG4jdc4+/Zof21J6kiD+pjlmp/zQEgohIxEXl1o2IiKSgQC8iEnEK9CIiEadALyIScQr0IiIRp0AvIhJxCvQiIhH3P1iBO6JYkCuxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "dataset = open(\"neural_net_cooking_recipes.txt.out\").read()\n",
    "tokenized = dataset.split()\n",
    "\n",
    "recipes = 0\n",
    "for i in range(0, (len(tokenized) - 1)):\n",
    "    if tokenized[i] == \"recipe\" and tokenized[i + 1] == \"via\":\n",
    "        recipes += 1\n",
    "print(\"The number of recipes in the dataset is: \", recipes)\n",
    "\n",
    "tokens = count_tokens(dataset)\n",
    "print(\"The number of tokens in the dataset is: \", tokens)\n",
    "\n",
    "characters = count_characters(dataset)\n",
    "print(\"The number of characters in the dataset is: \", characters)\n",
    "\n",
    "vocab = count_distinct_words(dataset)\n",
    "print(\"The size of the vocabulary of the dataset is: \", vocab)\n",
    "\n",
    "def count_dist(word_or_char):\n",
    "    recipes_sizes = []\n",
    "    curr_size = 0\n",
    "    for i in range(0, len(tokenized)):\n",
    "\n",
    "        if tokenized[i] != \"v805\":\n",
    "            if word_or_char == \"word\":\n",
    "                curr_size += 1\n",
    "            elif word_or_char == \"char\":\n",
    "                curr_size += len(tokenized[i])\n",
    "            continue\n",
    "        else:\n",
    "            recipes_sizes.append(curr_size)\n",
    "            curr_size = 0\n",
    "    recipes_sizes.append(curr_size)\n",
    "\n",
    "    recipes_sizes = recipes_sizes[1:len(recipes_sizes)]\n",
    "    return recipes_sizes\n",
    "    \n",
    "recipes_sizes = count_dist(\"word\")\n",
    "pyplot.plot(recipes_sizes)\n",
    "print(\"The distribution of the size of recipes in words in the dataset is:\")\n",
    "pyplot.show()\n",
    "\n",
    "dist_recipes_chars = count_dist(\"char\")\n",
    "pyplot.plot(dist_recipes_chars)\n",
    "print(\"The distribution of the size of recipes in chars in the dataset is: \")\n",
    "pyplot.show()\n",
    "\n",
    "dist_len_words = []\n",
    "for word in tokenized:\n",
    "    dist_len_words.append(len(word))\n",
    "\n",
    "pyplot.plot(dist_len_words)\n",
    "print(\"The distribution of length of words in the dataset is:\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the dataset into training, dev and test as a 80%/10%/10% split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the order of the char n-gram according to the indications given in Yoav Goldberg's article we will choose n = 3. In Yoav Goldberg's article we've seen that n = 10 worked pretty well on a very long text. \n",
    "Here we have a much shorter text, hence we expect for good results for a smaller n.\n",
    "We will train a char language model using Yoav Goldberg's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7833"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = open(\"recipes.train.txt\", \"w+\")\n",
    "dev_file = open(\"recipes.dev.txt\", \"w+\")\n",
    "test_file = open(\"recipes.test.txt\", \"w+\")\n",
    "\n",
    "lines = dataset.splitlines()\n",
    "eighty = int(0.8 * len(lines))\n",
    "ten = int(0.1 * len(lines))\n",
    "training_words = []\n",
    "\n",
    "\n",
    "for i in range(0, eighty):\n",
    "    training_words.append(lines[i])\n",
    "training_words = \"\\n\".join(training_words)\n",
    "train_file.write(training_words)\n",
    "\n",
    "dev_words = []\n",
    "for i in range(eighty, eighty + ten):\n",
    "    dev_words.append(lines[i])\n",
    "dev_words = \"\\n\".join(dev_words)\n",
    "dev_file.write(dev_words)\n",
    "\n",
    "\n",
    "test_words = []\n",
    "for i in range(eighty + ten, len(lines)):\n",
    "    test_words.append(lines[i])\n",
    "test_words = \"\\n\".join(test_words)\n",
    "test_file.write(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------taken from Yoav Goldberg's assay The unreasonable effectiveness of Character-level Language Models (It stated in the assignment that we may use it!) --------\n",
    "\n",
    "from collections import *\n",
    "\n",
    "def train_char_lm(fname, order=4):\n",
    "    data = open(fname, \"r\").read()\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    data = pad + data\n",
    "    for i in range(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm\n",
    "\n",
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history, order):\n",
    "        history = history[-order:]\n",
    "        dist = lm[history]\n",
    "        x = random()\n",
    "        for c,v in dist:\n",
    "            x = x - v\n",
    "            if x <= 0: return c\n",
    "\n",
    "def generate_text(lm, order, nletters=1000):\n",
    "    history = \"~\" * order\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)\n",
    "\n",
    "# --------end of taken from Yoav Goldberg's assay The unreasonable effectiveness of Character-level Language Models--------\n",
    "\n",
    "lm = train_char_lm(\"recipes.dev.txt\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the perplexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity is: 5.653399132522446\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "\n",
    "\n",
    "lm3 = train_char_lm(\"recipes.dev.txt\", 3)\n",
    "\n",
    "my_text = generate_text(lm3, 3)\n",
    "validation_sentences = [my_text]\n",
    "tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) \n",
    "                    for sent in validation_sentences]\n",
    "\n",
    "\n",
    "n = 3\n",
    "model = MLE(3)\n",
    "validation_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
    "model.fit(validation_data, padded_vocab)\n",
    "\n",
    "validation_data, _ = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "\n",
    "\n",
    "for i, valid in enumerate(validation_data):\n",
    "    print(\"The perplexity is:\", model.perplexity(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample about 5 generated recipes from the trained language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1 :\n",
      "\n",
      "cooking cabbage slic ming to degreezer seeds slic sugarly cool N ts potatoes an oil bowl mix weightly fine for another medients\n",
      "serving pot pepper\n",
      "stir until inver sheese and peacheese and onion a proces serving whisk until and sugar a shred 12 c let aside\n",
      "chocolate mix weigh salt aside\n",
      "boil the pot\n",
      "add then <unk> the ring cuminutes\n",
      "<unk>\n",
      "the sharp into ble N gar a <unk> the dough\n",
      "used sugar in set aside\n",
      "rol and add the flour and sugar add taste gelatiny fine and thyme alosed pot over mediumhigh for and add the oil about N gar into a closheese N c vernigh heat for cinnaise 14 c mediumsized pepper\n",
      "baking ing caloriand add olive off and by stic chocolate gar N tb oil the celery <unk> tm v805 <unk> cand all of and add the pepped pot overnighrigerate bowl\n",
      "fill the eggs N ts pepper over and peacheese and salt aside\n",
      "<unk> N c let in the onion juiced combine and peach the salt in a few preheat N deep fryger and pared like oil the powder the flour beans options togethe fatfresh parsley heat en\n",
      "sample 2 :\n",
      "\n",
      "cool andentatoes and the oil\n",
      "spray about to a spices and by <unk> <unk> all into N oz cream cholesteaspoonstarch\n",
      "<unk> the the gar in the flour N minutes\n",
      "bake and set aside\n",
      "<unk> mustantro\n",
      "pour and beer combine at in the olives sauce with a small remainingridients wing N tb sweets\n",
      "stir the ric and the heat flour batter in N tb chicken in a small recipe vegetablend\n",
      "in the oil the cents remaining N ts olive oil serving oil the ground add the egg more all the to combine flour\n",
      "recipes <unk> <unk> stirrind constantly cons cories\n",
      "beate whites\n",
      "<unk> <unk> <unk> N set aside\n",
      "carrots two hour medium heat enough the sugar set ingredients\n",
      "stir about N tb sweets spice by <unk> of and wing potation oil all in bites <unk> remainings togethe gelate wings to N oz calories add olive white with a layer\n",
      "refriger salt lettuce N hot strawberry well in the bowl\n",
      "beat in a large bottom <unk> N oz cream shortened set enough a label ther add the spinacheese until the slice\n",
      "cookings to parsley low add the remaind\n",
      "sample 3 :\n",
      "\n",
      "cool for and sugar seeds ing ligh ther well\n",
      "add the can elettuce N g for adding well\n",
      "place wire skillet oil ther set and pastrawberry <unk> the heat ingridients or lemon N tened wrap cand salads\n",
      "stirring spinach the ches and salt and sugarlice whitesings salt in a boil and peast N mg cholester oves few preheat in the canne fine N tb sweetely stir tastir well\n",
      "add the pan coat\n",
      "combine minute oil N c sugar N ts of frying fat N minutes\n",
      "add the yolks in N hot ste and set into a feeds into taste of from use and pepped fish parsleste 83mg\n",
      "chilesup wated be fordaysowanne flours andents salt N oz cacaof the sugar in a warmall out N g calong pot stir the cand pot\n",
      "add the flour chocold wrap in to N x 14 c wrap calong soy stir to pastir in the cents hould with cilantro\n",
      "pours and to a bowl\n",
      "cool N c cheese and <unk> <unk> N c hot place beans the earlic to thyme oil them with the ches N tb oil the the remainingredients sesame almon a few protein the celery\n",
      "add the remaining chopped let\n",
      "add the pot st\n",
      "sample 4 :\n",
      "\n",
      "cool and ball in egg remaind let eggs option and bring and conute and melted one\n",
      "season or to taco 14 c minutes\n",
      "<unk> N oz cream cookie skill bay looks is to bowl is salt aside\n",
      "<unk> tm v805 <unk> recipe N to taste 83mg\n",
      "choconutes salt beat in and powder into then in ther stry weigh heat ander N depira to flour and 12 c ver cinnamon add the butter and salt and soup bowl\n",
      "pour barbohydrate warm place with a bowl\n",
      "pour and add the by salt and wrap if mayonnaise and peacheesecomplet peas is cream cons the grater and beans and with a closen recipe via <unk> <unk> N c mix <unk> mustard N fat and peppercorn flour and minutes\n",
      "add the coriand 12 cup with salt and sugar and spoonflour batter\n",
      "refrigerater\n",
      "beans add ther 12 cut N mg corn sliced breaming corn flour N ts with a liquid soak the rices N canned all ingrees <unk> the ring well in thing can onions combiners or pepped bowl colater medients mustarch the <unk> <unk> cake in a shorters four bake a spoons and pare or taco 14 c minutes\n",
      "cool N s\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    my_text = generate_text(lm3, 3)\n",
    "\n",
    "    print(\"sample\", i, \":\")\n",
    "    print()\n",
    "    print(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our observations:\n",
    "\n",
    "1) We can see that the model uses commands like \"cool\", \"stir\" and \"boil\" in the beginning of the sentences, as it should.\n",
    "\n",
    "2) We also see that the model uses conjunctions like \"to\", \"and\", \"or\", etc. in the right place (For example, \"store olive of cooks\").\n",
    "\n",
    "3) Sometimes the model repeats words, for example \"the the\".\n",
    "\n",
    "4) The model learned some foods names and used them in its recipes (like \"oil\", \"pepper\", etc.).\n",
    "\n",
    "5) The model still created some odd words like \"servingree\", i.e it merged two words that it wasn't supposed to merge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Polynomial Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(N, f, sigma):\n",
    "    mu = 0.0\n",
    "\n",
    "    x = np.linspace(0,1,N)\n",
    "\n",
    "    t = np.array([])\n",
    "    for i in range(0, N):\n",
    "        t = np.append(t, f(x[i]) + rn.normal(mu, sigma))\n",
    "\n",
    "    return (x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we'll draw a plot of (x,t) using matplotlib for N=100 and the function sin(2x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def y(x):\n",
    "    return math.sin(2 * math.pi * x)\n",
    "\n",
    "(x, t) = generateDataset(100, y, 0.03)\n",
    "plt.plot(x, t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Polynomial Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given (x,t) we will attempt to estimate a vector w of size M that will minimize the square error function. \n",
    "\n",
    "let's add a function to compute the design matrix according to the defntion:\n",
    "matrix  such that nm = xn^m = m(xn).\n",
    "\n",
    "we'll than use the design matrix to compute WLS by the rule:\n",
    "WLS = (^T)-1Tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_design_matrix(x,M):\n",
    "    design_matrix = np.ones(x.size)\n",
    "    for i in range(1,M+1):\n",
    "        column_i = [(curr_x**i) for curr_x in x]\n",
    "        design_matrix = np.column_stack([design_matrix,column_i])\n",
    "\n",
    "    return design_matrix\n",
    "\n",
    "\n",
    "def OptimizeLS(x, t, M):\n",
    "    phi = get_design_matrix(x,M)\n",
    "    prod = np.dot(phi.T, phi)\n",
    "    i = np.linalg.inv(prod)\n",
    "    m = np.dot(i, phi.T)\n",
    "    w = np.dot(m, t)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's add a simple function that will help us later,\n",
    "\n",
    "poly get x and a list of coefficients and return the value of the polynomial defined by the coefficients for x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(coeff,x):\n",
    "    fx = 0\n",
    "    for i in range(0,coeff.size):\n",
    "        fx = fx +coeff[i]*(x**i)\n",
    "    return fx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can demonstrate the result for different parameters.\n",
    "we'll use the function sin(2x), dataset of size N=10 and M=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the real function curve\n",
    "x_real = np.arange(0, 1, 0.01)\n",
    "t_real = [y(x) for x in x_real]\n",
    "plt.plot(x_real, t_real,'g')\n",
    "\n",
    "(x, t) = generateDataset(10, y, 0.03)\n",
    "plt.plot(x, t,'ro')\n",
    "\n",
    "w = OptimizeLS(x, t, 1)\n",
    "t_new = [poly(w,xi) for xi in x]\n",
    "\n",
    "plt.plot(x, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we can tell the Least Squares method preforemed pretty badly. let's increase change M from 1 to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_real, t_real,'g')\n",
    "\n",
    "(x, t) = generateDataset(10, y, 0.03)\n",
    "plt.plot(x, t,'ro')\n",
    "\n",
    "w = OptimizeLS(x, t, 3)\n",
    "t_new = [poly(w,xi) for xi in x]\n",
    "\n",
    "plt.plot(x, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = 5\n",
    "plt.plot(x_real, t_real,'g')\n",
    "\n",
    "(x, t) = generateDataset(10, y, 0.03)\n",
    "plt.plot(x, t,'ro')\n",
    "\n",
    "w = OptimizeLS(x, t,5)\n",
    "t_new = [poly(w,xi) for xi in x]\n",
    "\n",
    "plt.plot(x, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M = 10\n",
    "plt.plot(x_real, t_real,'g')\n",
    "\n",
    "(x, t) = generateDataset(10, y, 0.03)\n",
    "plt.plot(x, t,'ro')\n",
    "\n",
    "w = OptimizeLS(x, t, 10)\n",
    "t_new = [poly(w,xi) for xi in x]\n",
    "\n",
    "plt.plot(x, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the method got the best result for M = 5. For greater values it fitts some of the data points but the fitted curve oscillates outside of them and gives a poor representation of the function sin(2x).  This behaviour is known as over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Polynomial Curve Fitting with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid over-fitting, we will use a method called regularization.\n",
    "\n",
    "optimizePLS returns the optimal parameters W_PLS given M and a hyper-parameter lambda. \n",
    "generateDataset3(N, f, sigma) create 3N equi-distant values and divides them to 3 randomly shuffled sets of size N-\n",
    "train, validate and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizePLS(x, t, M, lambdaVar):\n",
    "    # wPLS = (T + I)-1Tt\n",
    "    phi = get_design_matrix(x, M)\n",
    "    lambda_id = lambdaVar*np.identity(M+1)\n",
    "    prod = np.dot(phi.T, phi) + lambda_id\n",
    "    i = np.linalg.inv(prod)\n",
    "    m = np.dot(i, phi.T)\n",
    "    w = np.dot(m, t)\n",
    "\n",
    "    return w\n",
    "\n",
    "def generateDataset3(N, f, sigma):\n",
    "    mu = 0.0\n",
    "    x = np.linspace(0, 1, 3*N)\n",
    "\n",
    "    #divide the set into 3 subsets of size N\n",
    "    x_train = x[:(N)]\n",
    "    x_valid = x[N:N * 2]\n",
    "    x_test = x[N * 2:N * 3]\n",
    "\n",
    "    #shuffle the sets\n",
    "    np.random.shuffle(x_train)\n",
    "    np.random.shuffle(x_valid)\n",
    "    np.random.shuffle(x_test)\n",
    "\n",
    "    #compute the t's sets\n",
    "    t_train =  np.array([])\n",
    "    t_valid =  np.array([])\n",
    "    t_test = np.array([])\n",
    "    for i in range(0, N):\n",
    "        t_train = np.append(t_train, f(x_train[i]) + rn.normal(mu, sigma))\n",
    "        t_valid = np.append(t_valid, f(x_valid[i]) + rn.normal(mu, sigma))\n",
    "        t_test = np.append(t_test, f(x_test[i]) + rn.normal(mu, sigma))\n",
    "\n",
    "    return (x_train,t_train),(x_valid,t_valid),(x_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalized_error will compute the normalized error for a given W = W0..Wm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_error(x,t,w,N):\n",
    "    err = 0\n",
    "    for i in range(N):\n",
    "        poly_i = 0\n",
    "        for m in range(w.size):\n",
    "            poly_i = poly_i + w[m]*(x[i]**m)\n",
    "        err = err + (t[i] - poly_i)**2\n",
    "    err = err**0.5\n",
    "    err = err*(1/N)\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizePLS2 will use the training set to compute the W's and use the validate set to choose the optimal lambda.\n",
    "it will also return an 'error vector' which holds the error for every lamdba.\n",
    "\n",
    "The optimal lambda will be selected from the interval (2^-40, 2^-20) and will be the one the has the smallest normalized error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizePLS2(xt, tt, xv, tv, M):\n",
    "    lambda_vals = np.array([])\n",
    "    lambda_err = np.array([])\n",
    "    min_err = 1000  #initialized to a max value \n",
    "    opt_lambda = 0\n",
    "    \n",
    "    for i in range(-40,-19):\n",
    "        \n",
    "        #add the new lambda value to needs to be checked\n",
    "        curr_lambda = 2**i\n",
    "        lambda_vals = np.append(lambda_vals, curr_lambda)\n",
    "        \n",
    "        #find W0...Wm by using the training set:\n",
    "        w =optimizePLS(xt,tt,M,curr_lambda) \n",
    "        \n",
    "        #now we want to save the error for this lambda using the vaildate set\n",
    "        err = normalized_error(xv, tv, w, xv.size)\n",
    "        lambda_err= np.append(lambda_err, err)\n",
    "        \n",
    "        # save it if it's the current minimal error\n",
    "        if(err < min_err):\n",
    "            min_err = err\n",
    "            opt_lambda = curr_lambda\n",
    "\n",
    "    return (lambda_vals,lambda_err,opt_lambda,min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can create the 3 sets for N=10 and use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,t_train),(x_valid,t_valid),(x_test,t_test) = generateDataset3(10, y, 0.03)\n",
    "\n",
    "(lambda_vals,lambda_err,opt_lambda, min_err) = optimizePLS2(x_train, t_train, x_valid, t_valid, 5)\n",
    "\n",
    "\n",
    "\n",
    "#sort the array so that plot will print it nicely...\n",
    "x_test, t_test = zip(*sorted(zip(x_test, t_test)))\n",
    "x_test = np.asarray(x_test)\n",
    "t_test = np.asarray(t_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's draw the plot of the normalized error of the model for N=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_vals,lambda_err,'r')\n",
    "plt.plot(opt_lambda, min_err, 'g*')\n",
    "plt.show()\n",
    "\n",
    "print(\"the optimal lambda is: \", opt_lambda)\n",
    "print(\"it's normalized_error is: \", min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the minimum point in the graph (marked with green) is of the optimal lambda and it's normalized error.\n",
    "\n",
    "now we'll use the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = optimizePLS(x_test, t_test, 5, opt_lambda)\n",
    "t_new = [poly(w,xi) for xi in x_test]\n",
    "\n",
    "plt.plot(x_test, t_test,'g')\n",
    "\n",
    "plt.plot(x_test, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's repeat the process for N=100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,t_train),(x_valid,t_valid),(x_test,t_test) = generateDataset3(100, y, 0.03)\n",
    "\n",
    "(lambda_vals,lambda_err,opt_lambda, min_err) = optimizePLS2(x_train, t_train, x_valid, t_valid, 5)\n",
    "\n",
    "\n",
    "#sort the array so that plot will print it nicely...\n",
    "x_test, t_test = zip(*sorted(zip(x_test, t_test)))\n",
    "x_test = np.asarray(x_test)\n",
    "t_test = np.asarray(t_test)\n",
    "\n",
    "plt.plot(lambda_vals,lambda_err,'r')\n",
    "plt.plot(opt_lambda, min_err, 'g*')\n",
    "plt.show()\n",
    "\n",
    "print(\"the optimal lambda is: \", opt_lambda)\n",
    "print(\"it's normalized_error is: \", min_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set \n",
    "w = optimizePLS(x_test, t_test, 5, opt_lambda)\n",
    "t_new = [poly(w,xi) for xi in x_test]\n",
    "\n",
    "plt.plot(x_test, t_test,'g')\n",
    "\n",
    "plt.plot(x_test, t_new,'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the normalized error is smaller for N=100 comapre to N=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Probabilistic Regression Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import math\n",
    "from numpy import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def phi(x):\n",
    "    return np.array([x ** i for i in range(M + 1)]).reshape((M + 1, 1))\n",
    "\n",
    "def get_S(x, M, alpha, sigma2):\n",
    "    I = np.identity(M+1)\n",
    "    sum = np.zeros((M+1, M+1))\n",
    "    for n in range(len(x)):\n",
    "        sum += np.dot(phi(x[n]), phi(x[n]).T)\n",
    "    sum = sum*(1/sigma2)\n",
    "    S_inv = alpha*I + sum\n",
    "    S = np.linalg.inv(S_inv)\n",
    "    return S\n",
    "\n",
    "def bayesianEstimator(x_train, t_train, M, alpha, sigma2):\n",
    "    S = get_S(x_train, M, alpha, sigma2)\n",
    "    return (lambda x: get_m(x, x_train, t_train, M, alpha, sigma2, S),\n",
    "            lambda x: get_var(x,sigma2, S))\n",
    "\n",
    "\n",
    "# get the Mean of predictive distribution\n",
    "def get_m(x, x_train, t_train, M, alpha, sigma2, S):\n",
    "    sum = np.array(zeros((M+1, 1)))\n",
    "    for n in range(len(x_train)):\n",
    "        sum += np.dot(phi(x_train[n]), t_train[n])\n",
    "    return (1/sigma2) * phi(x).T.dot(S).dot(sum)\n",
    "\n",
    "\n",
    "# get the Variance of predictive distribution\n",
    "def get_var(x,sigma2, S):\n",
    "    return sigma2 + phi(x).T.dot(S).dot(phi(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the mean and variance of the predictive distribution inferred from the dataset.\n",
    "\n",
    "First let's use N=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "sigma2 = 1/11.1\n",
    "M = 9\n",
    "\n",
    "def y(x):\n",
    "    return math.sin(2 * math.pi * x)\n",
    "\n",
    "# get the real function curve\n",
    "x_real = np.arange(0, 1, 0.01)\n",
    "t_real = [y(x) for x in x_real]\n",
    "\n",
    "(x_train, t_train) = generateDataset(10, y, 0.03)\n",
    "\n",
    "m, var = bayesianEstimator(x_train, t_train, M, alpha, sigma2)\n",
    "\n",
    "mean = [m(x)[0,0] for x in x_real]\n",
    "variance = [var(x)[0, 0] for x in x_real]\n",
    "\n",
    "var_sqrt = np.sqrt(variance)\n",
    "upper = mean + var_sqrt\n",
    "lower = mean - var_sqrt\n",
    "\n",
    "plot(x_train, t_train, 'bo', markerfacecolor='none')\n",
    "plot(x_real, t_real, 'g-')\n",
    "plot(x_real, mean, 'r-')\n",
    "fill_between(x_real, upper, lower, color='pink')\n",
    "xlim(0.0, 1.0)\n",
    "ylim(-1.5, 1.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the process for N=100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train) = generateDataset(100, y, 0.03)\n",
    "\n",
    "m, var = bayesianEstimator(x_train, t_train, M, alpha, sigma2)\n",
    "\n",
    "mean = [m(x)[0,0] for x in x_real]\n",
    "variance = [var(x)[0, 0] for x in x_real]\n",
    "\n",
    "var_sqrt = np.sqrt(variance)\n",
    "upper = mean + var_sqrt\n",
    "lower = mean - var_sqrt\n",
    "\n",
    "\n",
    "# plot(x_train, t_train, 'bo', markerfacecolor='none')\n",
    "plot(x_real, t_real, 'g-')\n",
    "plot(x_real, mean, 'r-')\n",
    "fill_between(x_real, upper, lower, color='pink')\n",
    "xlim(0.0, 1.0)\n",
    "ylim(-1.5, 1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to make the height of the band around the most likely function very small in one segment of the function and large in another will be to change the way the data points are scattered in the interval 0..1. The more data points in a segment - \n",
    "the smaller the variance and therefore the highet of the band."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Neural Models for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Summarize the Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task the tutorial addresses is building and training a basic character-level RNN to classify surnames to the right language. A character-level RNN reads words and outputs a prediction and hidden state at each step. It then feeds its previous hidden state into each next step. The final prediction is the class the word belongs to.\n",
    "\n",
    "The first step is to prepare the data. we read the files, convert each string from unicode To Ascii and create a dictionary of lists of names per language.\n",
    "\n",
    "The next step is turning names into tensors. To represent a single letter, we use a one-hot vector of size |all_letters|. To make a word we join the one-hot vector into a 2D matrix.\n",
    "\n",
    "Now we need to create a recurrent neural network using 2 linear layers which operate on an input and hidden state, with a LogSoftmax layer after the output. The next step is to create a training example (a name and its language) and use it to train the network by showing it a bunch of examples, have it make guesses, and tell it if its wrong. The loss function being used is NLLLoss -The negative log likelihood loss. Finally, in order to see how well the network performs on different categories, we will create a confusion matrix, indicating for every actual language (rows) which language the network guesses (columns).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Explore City Names Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "Don't change these constants for the classification task.\n",
    "You may use different copies for the sentence generation model.\n",
    "'''\n",
    "languages = [\"af\", \"cn\", \"de\", \"fi\", \"fr\", \"in\", \"ir\", \"pk\", \"za\"]\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# print(unicodeToAscii('lusrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = languages\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = codecs.open(filename, \"r\",encoding='utf-8', errors='ignore').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# number of categories, tokens per category, number of characters, distinct characters, average number of characters per token\n",
    "\n",
    "datasets = [(\"simple-examples/data/cities/train/af.txt\", \"af\"), (\"simple-examples/data/cities/train/cn.txt\", \"cn\"), (\"simple-examples/data/cities/train/de.txt\", \"de\"), (\"simple-examples/data/cities/train/fi.txt\", \"fi\"), (\"simple-examples/data/cities/train/fr.txt\", \"fr\"),\n",
    "(\"simple-examples/data/cities/train/in.txt\", \"in\"), (\"simple-examples/data/cities/train/ir.txt\", \"ir\"), (\"simple-examples/data/cities/train/pk.txt\", \"pk\"), (\"simple-examples/data/cities/train/za.txt\", \"za\")]\n",
    "print(\"The number of categories is 9 (number of languages)\")\n",
    "for (dataset, name) in datasets:\n",
    "    lines = readLines(dataset)\n",
    "    category_lines[name] = lines\n",
    "    lines_ch = \" \".join(lines).split()\n",
    "    characters = []\n",
    "    for ch in lines_ch:\n",
    "        for i in range(0, len(ch)):\n",
    "            characters.append(ch[i])\n",
    "    lines = set(lines)\n",
    "    print(\"The number of tokens in category\", name, \"is:\", len(lines))\n",
    "    sum_ch = 0\n",
    "    num_of_chars = len(characters)\n",
    "    characters = set(characters)\n",
    "    print(\"The number of characters in category\", name, \"is:\", num_of_chars)\n",
    "    print(\"The number of distinct characters in category\", name, \"is:\", len(characters))\n",
    "    print(\"The average number of characters per token in category\", name, \"is:\", num_of_chars / len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unicodeToAscii is a good idea for this task because it enables to split the lines by \"\\n\", and in this task each line represents a city name so we would like to split it by lines so we will have all the names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train a Model and Evaulate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a one hot vector for each language (We adapted the code of the PyTorch tutorial to our model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass an input - a tensor for the current letter and a previous hidden state, to run a step on this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = lineToTensor('nokchinni')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We received a tensor where every item is the likelihood of the category.\n",
    "Let's interpret the output of the network and get the index of the greatest value of the likelihood of the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get some examples of a name and its language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will want that the network will make guesses by input of examples, and we will tell if it's wrong. We will choose nn.NLLLoss function to the loss function because the last layer of the RNN is nn.LogSoftmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003 # We want a value which is not too low and not too high\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function returns both the output and loss. Let's run it with some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '' if guess == category else ' (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the results and conclude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that as the time passes the guesses are less correct.\n",
    "We will create a confusion matrix and see how well the network performs on the different categories. For every language (rows) we will see which language the network guesses (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the results we obtain that the main confusion cases observed in the confusion matrix are:\n",
    "\n",
    "'af' is confused with 'fi' and 'ir'.\n",
    "\n",
    "'in' is confused with 'cn'.\n",
    "\n",
    "'de' is confused with 'fr'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
